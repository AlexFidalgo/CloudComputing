{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visão Geral dos Conceitos de Nuvem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computação em Nuvem é a entrega <span style=\"color:brown;\">sob demanda</span> de <span style=\"color:yellow;\">poder computacional</span>, <span style=\"color:yellow;\">banco de dados</span>, <span style=\"color:yellow;\">armazenamento</span>, <span style=\"color:yellow;\">aplicativos</span> e outros recursos de TI <span style=\"color:brown;\">pela internet</span> com uma definição de <span style=\"color:brown;\">preço conforme o uso</span>.\n",
    "\n",
    "Permite que a organização deixe de pensar na infraestrutura como hardware e passe a pensar nela (e usá-la) como software.\n",
    "\n",
    "No modelo de computação tradicional, a infraestrutura é hardware. Isso exige espaço, equipe, segurança física, planejamento, despesas de capital e provisionamento de capacidade por meio de tentativa de adivinhar os picos máximos teóricos. Existe um ciclo longo de aquisição de hardware. \n",
    "\n",
    "Já no modelo de computação em nuvem, a infraestrutura é software. As soluções são flexíveis, podem mudar com mais rapidez, facilidade e economia do que as soluções de hardware e eliminam as tarefas monolíticas de trabalho pesado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula01/iaas_saas_paas.png\" alt=\"IaaS, PaaS, and SaaS Comparison\" style=\"width:40%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Public**: This model represents the use of cloud services provided by third-party cloud service providers. All the infrastructure and services are managed by the provider, and the user can access and utilize these resources over the internet. It offers scalability, flexibility, and a pay-as-you-go pricing model.\n",
    "\n",
    "- **Hybrid**: This model combines both cloud and on-premises infrastructure. It allows data and applications to be shared between them, providing greater flexibility and more deployment options. This approach can help businesses balance between having control over critical data and leveraging the benefits of cloud computing.\n",
    "\n",
    "- **Private**: In this model, the cloud infrastructure is hosted within an organization’s own data center. It offers greater control over data, enhanced security, and compliance with regulatory requirements. This is ideal for organizations that have stringent data privacy needs and require complete control over their IT environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula01/aws.png\" alt=\"IaaS, PaaS, and SaaS Comparison\" style=\"width:70%;\"/>\n",
    "\n",
    "\n",
    "### Security\n",
    "- **Traditional IT:**\n",
    "  - **Firewalls:** Used to protect the network from unauthorized access.\n",
    "  - **ACLs:** Access Control Lists used to manage user permissions.\n",
    "  - **Administradores:** Administrators who manage security policies and configurations.\n",
    "- **AWS:**\n",
    "  - **Grupos de segurança (Security Groups):** Control the inbound and outbound traffic to AWS resources.\n",
    "  - **ACLs de rede (Network ACLs):** Provide an additional layer of security at the subnet level.\n",
    "  - **IAM:** Identity and Access Management to control user permissions and access to AWS resources.\n",
    "\n",
    "### Networking\n",
    "- **Traditional IT:**\n",
    "  - **Roteador (Router):** Directs data packets between networks.\n",
    "  - **Pipeline de rede (Network Pipeline):** Manages the flow of data in and out of the network.\n",
    "  - **Switch:** Connects devices within the same network to enable communication.\n",
    "- **AWS:**\n",
    "  - **Elastic Load Balancing:** Distributes incoming application traffic across multiple targets.\n",
    "  - **Amazon VPC:** Virtual Private Cloud to provision a logically isolated section of the AWS cloud.\n",
    "\n",
    "### Compute\n",
    "- **Traditional IT:**\n",
    "  - **Servidores locais (Local Servers):** Physical servers hosted on-premises.\n",
    "- **AWS:**\n",
    "  - **AMI:** Amazon Machine Images to launch virtual servers.\n",
    "  - **Instâncias do Amazon EC2:** Virtual servers in the cloud providing scalable computing capacity.\n",
    "\n",
    "### Storage and Databases\n",
    "- **Traditional IT:**\n",
    "  - **DAS (Direct-Attached Storage):** Storage directly attached to the server.\n",
    "  - **SAN (Storage Area Network):** High-speed network of storage devices.\n",
    "  - **NAS (Network-Attached Storage):** Dedicated file storage connected to a network.\n",
    "  - **RDBMS (Relational Database Management Systems):** Databases hosted on-premises.\n",
    "- **AWS:**\n",
    "  - **Amazon EBS:** Elastic Block Store for persistent block storage.\n",
    "  - **Amazon EFS:** Elastic File System for scalable file storage.\n",
    "  - **Amazon S3:** Simple Storage Service for scalable object storage.\n",
    "  - **Amazon RDS:** Relational Database Service for managed relational databases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cloud solution often represents a shift from Capital Expenditure (CapEx) to Operational Expenditure (OpEx).\n",
    "\n",
    "Devido ao uso agregado de todos os clientes, a AWS pode proporcionar grande economia de escala e repassar os descontos para os clientes.\n",
    "\n",
    "<img src=\"figs/aula01/scalability.png\" alt=\"IaaS, PaaS, and SaaS Comparison\" style=\"width:70%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução à Amazon Web Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um <span style=\"color: #5a2ca0;\">serviço web</span> é qualquer software disponibilizado pela Internet que usa um <span style=\"color: #5a2ca0;\">formato padronizado</span>, como Extensible Markup Language (XML) ou JavaScript Object Notation (JSON), para a solicitação e resposta de uma interação de <span style=\"color: #5a2ca0;\">Application Programming Interface (API)</span>.\n",
    "\n",
    "O pagamento se dá apenas pelos serviços individuais necessários, pelo tempo de utilização.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de Solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula01/sol1.png\" alt=\"IaaS, PaaS, and SaaS Comparison\" style=\"width:50%;\"/>\n",
    "\n",
    "1. **Usuários (Users)**\n",
    "   - **Users**: Represent the end-users who interact with the application or services hosted on the AWS cloud.\n",
    "\n",
    "2. **Nuvem AWS (AWS Cloud)**\n",
    "   - **AWS Cloud**: The overall cloud environment provided by Amazon Web Services (AWS).\n",
    "\n",
    "3. **Virtual Private Cloud (VPC)**\n",
    "   - **Virtual Private Cloud (VPC)**: A logically isolated section of the AWS cloud where you can launch AWS resources in a virtual network that you define. It provides complete control over the virtual networking environment, including selection of your IP address range, creation of subnets, and configuration of route tables and network gateways.\n",
    "\n",
    "4. **Amazon EC2**\n",
    "   - **Amazon EC2 (Elastic Compute Cloud)**: Provides resizable compute capacity in the cloud. It allows you to run virtual servers, known as instances, to host your applications and services.\n",
    "\n",
    "5. **Amazon DynamoDB**\n",
    "   - **Amazon DynamoDB**: A fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. It is used to store and retrieve any amount of data, and serve any level of request traffic.\n",
    "\n",
    "6. **Amazon S3**\n",
    "   - **Amazon S3 (Simple Storage Service)**: An object storage service that offers industry-leading scalability, data availability, security, and performance. It is used to store and protect any amount of data for a range of use cases, such as data lakes, websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics.\n",
    "\n",
    "- **Users** interact with the application through the **Nuvem AWS (AWS Cloud)**.\n",
    "- **Virtual Private Cloud (VPC)** acts as the main networking component, isolating the environment and controlling network traffic.\n",
    "- **Amazon EC2** instances run within the VPC and handle the compute workload.\n",
    "- **Amazon DynamoDB** is used for database storage, interacting with EC2 instances to handle data operations.\n",
    "- **Amazon S3** is used for storing and retrieving files and objects, providing durable and scalable storage.\n",
    "- The components are interconnected within the VPC, ensuring secure and efficient communication between the services.\n",
    "\n",
    "- **Redes (Networking)**\n",
    "  - Includes services like VPC which provides networking capabilities.\n",
    "- **Computação (Compute)**\n",
    "  - Includes services like Amazon EC2 which provide computing power.\n",
    "- **Banco de dados (Database)**\n",
    "  - Includes services like Amazon DynamoDB for database management.\n",
    "- **Armazenamento (Storage)**\n",
    "  - Includes services like Amazon S3 for object storage.\n",
    "\n",
    "This simple solution example demonstrates how different AWS services can be combined to create a secure, scalable, and efficient cloud infrastructure. The interaction between compute, database, and storage services within a Virtual Private Cloud (VPC) ensures that the application can handle various workloads and provide reliable service to end-users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Três maneiras de interagir com a AWS\n",
    "\n",
    "1. **Console de Gerenciamento da AWS**\n",
    "   - Interface gráfica fácil de usar\n",
    "   - Provides a user-friendly graphical interface to interact with AWS services.\n",
    "\n",
    "2. **Interface da linha de comando (CLI da AWS)**\n",
    "   - Acesso a serviços por comandos ou scripts específicos\n",
    "   - Allows access to AWS services using command line commands or specific scripts.\n",
    "\n",
    "3. **Kits de desenvolvimento de software (SDKs)**\n",
    "   - Acesse serviços diretamente do seu código (como Java, Python e outros)\n",
    "   - Enables access to AWS services directly from your code in various programming languages like Java, Python, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  AWS Cloud Adoption Framework (CAF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O AWS CAF oferece orientação e melhores práticas para ajudar as organizações a criar uma abordagem abrangente para a computação em nuvem em toda a organização e durante todo o ciclo de vida de TI para acelerar a adoção bem-sucedida da nuvem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NIST Definition of Cloud Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model is composed of five essential characteristics, three service models, and four deployment models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essential Characteristics:\n",
    "\n",
    "- **On-demand self-service.** A consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with each service provider.\n",
    "\n",
    "- **Broad network access.** Capabilities are available over the network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, tablets, laptops, and workstations).\n",
    "\n",
    "- **Resource pooling.** The provider’s computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand. There is a sense of location independence in that the customer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter). Examples of resources include storage, processing, memory, and network bandwidth.\n",
    "\n",
    "- **Rapid elasticity.** Capabilities can be elastically provisioned and released, in some cases automatically, to scale rapidly outward and inward commensurate with demand. To the consumer, the capabilities available for provisioning often appear to be unlimited and can be appropriated in any quantity at any time.\n",
    "\n",
    "- **Measured service.** Cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Models\n",
    "\n",
    "#### Software as a Service (SaaS)\n",
    "The capability provided to the consumer is to use the provider’s applications running on a cloud infrastructure. The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration settings.\n",
    "\n",
    "A cloud infrastructure is the collection of hardware and software that enables the five essential characteristics of cloud computing. The cloud infrastructure can be viewed as containing both a physical layer and an abstraction layer. The physical layer consists of the hardware resources that are necessary to support the cloud services being provided, and typically includes server, storage and network components. The abstraction layer consists of the software deployed across the physical layer, which manifests the essential cloud characteristics. Conceptually the abstraction layer sits above the physical layer.\n",
    "\n",
    "#### Platform as a Service (PaaS)\n",
    "\n",
    "The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider (this capability does not necessarily preclude the use of compatible programming languages, libraries, services, and tools from\n",
    "other sources). The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment.\n",
    "\n",
    "#### Infrastructure as a Service (IaaS)\n",
    "\n",
    "The capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, and deployed applications; and possibly limited control of select networking components (e.g., host firewalls)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Models\n",
    "\n",
    "- **Private cloud.** The cloud infrastructure is provisioned for exclusive use by a single organization comprising multiple consumers (e.g., business units). It may be owned, managed, and operated by the organization, a third party, or some combination of them, and it may exist on or off premises.\n",
    "\n",
    "- **Community cloud.** The cloud infrastructure is provisioned for exclusive use by a specific community of consumers from organizations that have shared concerns (e.g., mission, security requirements, policy, and compliance considerations). It may be owned, managed, and operated by one or more of the organizations in the community, a third party, or some combination of them, and it may exist on or off premises.\n",
    "\n",
    "- **Public cloud.** The cloud infrastructure is provisioned for open use by the general public. It may be owned, managed, and operated by a business, academic, or government organization, or some combination of them. It exists on the premises of the cloud provider.\n",
    "\n",
    "- **Hybrid cloud.** The cloud infrastructure is a composition of two or more distinct cloud infrastructures (private, community, or public) that remain unique entities, but are bound together by standardized or proprietary technology that enables data and application portability (e.g., cloud bursting for load balancing between clouds).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos de Máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PC Ubuntu 22.04 ou 24.04  (mínimo 8GBytes RAM, 4 núcleos, virtualização habilitada no BIOS, hyperthreading desabilitada, 32Gytes de disco livres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "virtualbox: é difícil montar um cluster de máquinas\n",
    "\n",
    "core: core físico, sem hyperthread\n",
    "\n",
    "Um número típico de cores para uma máquina intel é de 4 a 6 cores (em cada socket, de 4 a 6 cores).\n",
    "Para rodar as cargas de processamento, vamos colocar um servidor ubuntu, com 2 GB. Podemos chegar até 3 máquinas virtuais; assumindo que alocamos 2 cores por máquina virtual, precisaria de 6 cores.\n",
    "\n",
    "Precisamos de 8 GB de RAM e 6 cores.\n",
    "\n",
    "Em computação em nuvem, tipicamente, há 4 máquinas virtuais para cada core físico. Colocando 1 máquina virtual por core, encareceria muito o custo para o cliente. Mas para nós no curso, é importante ter mais para podermos avaliar o que está acontecendo, para não termos influência negativa de uma máquina virtual em outra. Procuraremos colocar uma máquina virtual para cada core; e idealmente, fazer pinning: fixar uma máquina virtual para core (esse cenário, por questões comerciais, há 4 máquinas virtuais por core).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VirtualBox and Clustering\n",
    "\n",
    "1. **VirtualBox**: This is a software application that allows you to create and run virtual machines on your computer. A virtual machine (VM) is a software emulation of a physical computer.\n",
    "\n",
    "2. **Cluster of Machines**: In a cloud computing context, a cluster refers to a group of interconnected computers that work together as a single system. Creating a cluster of VMs can be complex because it involves configuring multiple VMs to communicate and cooperate effectively.\n",
    "\n",
    "### CPU and Cores\n",
    "\n",
    "1. **Core**: A core is a processing unit within a CPU. It is capable of executing instructions from a computer program. Modern CPUs often have multiple cores, allowing them to perform multiple tasks simultaneously.\n",
    "\n",
    "2. **Physical Core**: This refers to the actual hardware core in the CPU.\n",
    "\n",
    "3. **Hyperthreading**: This is a technology used by some Intel processors that allows a single physical core to act like two logical cores, which can improve performance for certain types of tasks. Your professor is specifying to use physical cores, not hyperthreaded ones.\n",
    "\n",
    "### Machine Requirements\n",
    "\n",
    "1. **Number of Cores**: Typical modern Intel CPUs have 4 to 6 cores per CPU socket. For the course, they suggest using 6 cores for running VMs.\n",
    "\n",
    "2. **RAM**: For running the VMs, 8 GB of RAM is recommended.\n",
    "\n",
    "### Virtual Machines (VMs)\n",
    "\n",
    "1. **Server Setup**: The course will use Ubuntu as the server operating system, with each VM allocated 2 GB of RAM.\n",
    "\n",
    "2. **Number of VMs**: You can create up to 3 VMs, each using 2 cores. This totals 6 cores for 3 VMs (2 cores per VM).\n",
    "\n",
    "### Cloud Computing and VM Allocation\n",
    "\n",
    "1. **VM to Core Ratio**: In a commercial cloud environment, it's common to have multiple VMs sharing a single physical core to optimize resource usage and reduce costs. Typically, there might be 4 VMs per physical core.\n",
    "\n",
    "2. **Course Setup**: For educational purposes, it's important to minimize interference between VMs. Therefore, your professor recommends using a 1-to-1 ratio (one VM per core) and ideally performing \"pinning,\" which means fixing each VM to a specific core to ensure stable performance and accurate monitoring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requisitos:\n",
    "- Máquina Ubuntu 22.04/24.04 BARE METAL\n",
    "- 4/6 CORES\n",
    "- 8/16 GBYTES RAM\n",
    "- ESPAÇO DE 32GBYTES DISCO PARA AS VMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtualização, Hypervisors e KVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation of the software or hardware upon which other software runs. This simulated environment is called a virtual machine.\n",
    "\n",
    "A methodology for emulation or abstraction of hardware resources that enables complete execution stacks including software applications to run on it.\n",
    "\n",
    "The use of an abstraction layer to simulate computing hardware so that multiple operating systems can run on a single computer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mainframe is a large, powerful computer system primarily used by large organizations for critical applications, bulk data processing, and enterprise resource planning. Mainframes are known for their high reliability, scalability, and security, making them suitable for handling massive volumes of transactions and data.\n",
    "\n",
    "Eram caros; começou-se a estudar métodos para se ter o uso compartilhado dos recursos, também para instalação de mais de um sistema operacional. Queria-se colocar várias máquinas virtuais dentro do mainframe e, para cada máquina virtual, se ter um ambiente completamente isolado um do outro (se ter ambientes operacionais diferentes). Assim os diverso usuários poderiam executar seu trabalho de forma independente (sem interferência).\n",
    "\n",
    "Com o aparecimento de computadores menores, o interesse pela virtualização diminui (com a opção de computadores pessoais e uma máquina por usuário). Um retorno desse interesse veio na década de 90 com o aumento da capacidade computacional dos computadores (no caso, servidores).\n",
    "\n",
    "Houve outro boom no tópico quando se notou a possibilidade de implantar máquinas virtuais utilizando suporte de hardware. Desde 2010, há uma perda de desempenho dessas virtualizações clássicas em relação ao desempenho de virtualizações via **containers**.\n",
    "\n",
    "<img src=\"figs/aula02/taxonomy_of_virtualization.png\" alt=\"Taxonomy of Virtualization\" style=\"width:50%;\"/>\n",
    "\n",
    "Virtualization is the process of creating a virtual version of something, such as hardware platforms, storage devices, or network resources.\n",
    "\n",
    "**Categories of Virtualization**:\n",
    "   - **Execution Environment**:\n",
    "     - Virtualization of environments where processes run.\n",
    "   - **Storage**:\n",
    "     - Virtualization of storage devices.\n",
    "   - **Network**:\n",
    "     - Virtualization of network resources.\n",
    "\n",
    "Virtualization can be done at two primary levels: \n",
    "\n",
    "1. **Process Level**:\n",
    "   - **Technique**:\n",
    "     - **Emulation**:\n",
    "       - Creates an environment that mimics another system, allowing applications to run as if they are on the original hardware.\n",
    "     - **High-Level VM (Virtual Machine)**:\n",
    "       - Uses a high-level virtual machine to execute programs.\n",
    "     - **Multiprogramming**:\n",
    "       - Multiple programs run on a single processor by managing their execution.\n",
    "   - **Virtualization Model**:\n",
    "     - **Application**:\n",
    "       - Virtualization at the application level.\n",
    "     - **Programming Language**:\n",
    "       - Virtualization using programming languages.\n",
    "     - **Operating System**:\n",
    "       - Virtualization at the OS level.\n",
    "\n",
    "2. **System Level**:\n",
    "   - **Technique**:\n",
    "     - **Hardware-Assisted Virtualization**:\n",
    "       - Uses hardware features to improve the efficiency of virtualization.\n",
    "     - **Full Virtualization**:\n",
    "       - Complete simulation of the underlying hardware to run unmodified operating systems.\n",
    "     - **Paravirtualization**:\n",
    "       - A virtualization technique that presents a software interface to virtual machines that is similar, but not identical, to that of the underlying hardware.\n",
    "     - **Partial Virtualization**:\n",
    "       - Only some parts of the target environment are virtualized.\n",
    "   - **Virtualization Model**:\n",
    "     - **Hardware**:\n",
    "       - Virtualization at the hardware level.\n",
    "\n",
    "\n",
    "System Level: o foco maior é a virtualização do processador, mas há interesse na virtualização de outros itens (todo o entorno do processador é atualmente o gargalo do desempenho).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of \"Formal Requirements for Virtualizable Third Generation Architectures\" by Gerald J. Popek and Robert P. Goldberg\n",
    "\n",
    "The paper by Popek and Goldberg presents a formal analysis of the requirements for third generation computer architectures to support virtualization. The key contributions of the paper include defining what constitutes a virtual machine (VM), outlining the characteristics of a virtual machine monitor (VMM), and establishing the conditions under which a third generation architecture can support virtual machines.\n",
    "\n",
    "##### Key Concepts\n",
    "\n",
    "1. **Virtual Machine (VM)**: An efficient, isolated duplicate of a real machine, where programs running under a VM experience an environment identical to the real machine with only minor performance overhead.\n",
    "2. **Virtual Machine Monitor (VMM)**: A software layer that creates and manages virtual machines, providing an environment identical to the underlying hardware, maintaining control over system resources, and ensuring efficient execution of most instructions directly by the hardware.\n",
    "\n",
    "##### Formal Model\n",
    "\n",
    "- The authors develop a model of a third-generation-like computer system, specifying necessary assumptions about its behavior, state-space, and state transitions.\n",
    "- The model includes a processor with supervisor and user modes, relocation registers for memory addressing, and a set of conventional instructions.\n",
    "\n",
    "##### Conditions for Virtualization\n",
    "\n",
    "The paper establishes a critical condition for an architecture to support virtualization:\n",
    "- **Sensitive Instructions**: Instructions that can affect the hardware state in a way that could interfere with the operation of the VMM must be a subset of the privileged instructions. This ensures that any sensitive operation will trap to the VMM, allowing it to maintain control over system resources.\n",
    "\n",
    "##### Major Theorems\n",
    "\n",
    "1. **Theorem 1**: For any conventional third-generation computer, a VMM can be constructed if the set of sensitive instructions is a subset of the privileged instructions.\n",
    "2. **Theorem 2**: A conventional third generation computer is recursively virtualizable if it is virtualizable and a VMM without timing dependencies can be constructed for it.\n",
    "3. **Theorem 3**: A hybrid virtual machine monitor (HVM) can be constructed for any conventional third generation machine where user-sensitive instructions are a subset of privileged instructions.\n",
    "\n",
    "##### Practical Implications\n",
    "\n",
    "- The formal techniques provided in the paper can be applied to evaluate existing architectures and design new architectures to support virtualization.\n",
    "- The results have been used to modify existing systems, such as the DEC PDP-11/45, to support virtual machines.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "The paper concludes that while the model captures essential aspects of third generation virtual machines, some simplifications were made for presentation purposes. Empirical evidence suggests that additional complexities, such as I/O operations and asynchronous events, can be integrated into the model. The formal techniques outlined may also be applied to newer architectures designed to support virtualization without traditional VMM overhead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtualization is a core technology used for the implementation of cloud computing. It increases the utilization of resources such as processor, storage, network etc. by collecting various underutilized resources available in the form of a shared pool of resources built through the creation of Virtual Machines (VMs).\n",
    "\n",
    "The requirements in cloud environment are dynamic therefore there is always a need to move virtual machines within the same cloud or amongst different clouds. This is achieved through migration of VMs which results in several benefits such as saving energy of the host, managing fault tolerance if some host is not working properly and load balancing among all hosts.\n",
    "\n",
    "Cloud is a parallel and distributed computing system consisting of a **collection of inter connected and virtualized computers that are dynamically provisioned and presented as one or more unified computing resources** based on service level agreement (SLA) established through negotiation between the service provider and consumers.\n",
    "\n",
    "Virtualization creates an abstract layer over the actual hardware and software. It emulates a physical machine in software to run multiple operating systems on single machine hardware. The main goal of virtualization is to utilize the maximum capacity of available resources such as processor, storage and network. By creating virtual machines, it collaborates multiple unutilized resources into a shared resource pool and utilizes them by performing different tasks simultaneously to fulfill multiple user demands. These resources can be scaled on virtual machines (i.e. allocated dynamically).\n",
    "\n",
    "There can be various types of virtualizations like -\n",
    "\n",
    "- **Application Virtualization** – In this, application/s including operating system of host machine is moved to the virtual environment. It is a technology in which the application is present somewhere else but is accessed by the client computer. The application behaves same as the local application on the client system. For example - VMWare Thinapp, Oracle secure Global desktop, etc.\n",
    "\n",
    "- **Storage Virtualization** – It provides a virtual storage environment by collecting or combining various physical storages. Through this, distributed storage is managed in such a way as if it is one consolidated storage. After this virtualization, the availability of storage increases because now the applications do not have limited or a specific resource. The storage can be updated any time without affecting the performance of the application.\n",
    "\n",
    "- **Server Virtualization** – In this, existing server is moved into a virtual environment i.e. hypervisor, which is hosted on a physical server. The resources of server are hidden from clients and the physical server is divided into multiple virtual environments. Web server virtualization is one of the most popular examples of this technology used for providing low cost web hosting services.\n",
    "\n",
    "- **Hardware Virtualization** – This virtualization makes hardware components of real machine as virtual components. This technology hides all the physical components and details of actual computing platform from end users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtualization is done by using a **hypervisor**, a software which acts as an intemediator between virtual machine and physical hardware. It is used to create virtual machines.\n",
    "\n",
    "The hypervisor manages virtual hardware and guest operating system on the said hardware on a virtual platform. Hypervisor can be native (Type-1) or Hosted (Type-2).\n",
    "\n",
    "Type-1 hypervisor layer comes before the Operating System and runs on hardware directly to manage the guest Operating System. This type of virtualization is known as full virtualization.\n",
    "\n",
    "Type-2 hypervisor requires host Operating System to run it and the guest operating Systems are then managed by the hypervisor. This type of virtualization is called Para-virtualization.\n",
    "\n",
    "\n",
    "<img src=\"figs/aula02/Type-1-and-Type-2-Hypervisor.png\" alt=\"Taxonomy of Virtualization\" style=\"width:50%;\"/>\n",
    "\n",
    "These\n",
    "resources can be allocated or de-allocated dynamically on VMs allowing a single physical host to be converted into number of virtual hosts. Each virtual host delivers a secure and isolated environment for applications. These environments can be customized in the form of software and hardware platform according to the demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O sistema que suporta a implantação de MV é o gerenciador (ou monitor) de MV; também chamado de Hypervisor. O Hypervisor pode rodar em cima:\n",
    "\n",
    "- da plataforma de hardware (solução bare metal, **Tipo 1**) \n",
    "- de outro sistema operacional (**Tipo 2**).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnicas para Virtualização:\n",
    "\n",
    "- Complete Machine Emulation (Hosted Interpretation): É a mais poderosa de todas, permite a execução de código de qualquer processador na sua máquina, bastando que se tenha o emulador específico para aquele processador. Mas se precisa modelo do processador e olhar instrução por instrução (é muito lento). \n",
    "\n",
    "- Full Virtualization (Execução Direta): muito associada com hypervisor Tipo 1.\n",
    "\n",
    "    - Execução Direta com Trap-and-Emulate: nela, toda instrução que mexe com recursos sensíveis precisa ser executada de forma protegida. Gera-se problemas com x86.\n",
    "\n",
    "    - Execução Direta com Binary Translation: Exemplo: VMware's Dynamic Binary Translation. Faz simulação (não emulação). As instruções que são executadas a nível de usuário não requerem muito trabalho; já as execuções executadas a nível kernel (sistema operacional) requerem um software que traduz dinamicamente, sob demanda, as linhas de código para o código nativo do seu processador. A parte do código que não faz chamadas críticas é rodado rapidamente, em tempo de bare-metal (a execução vai direto pro processador). Mas a parte do código relacionada ao kernel roda mais devagar.\n",
    "\n",
    "    - Execução Direta com Hardware-Assisted Virtualization: Ex Hardware-Assisted CPU Virtualization (Intel VT-x). VT-x se refere ao processador, mas o desempenho depende de outros hardwares também. \n",
    "\n",
    "- Paravirtualization: Quando se necessita mudar o código para que ele fique ciente do virtualizador que se tem embaixo. O OS guest é recompilado sendo mapeado para o ambiente operacional para onde ele vá. A parte do usuário em si não precisa ser mudado (é jogado direto pra ser processado), precisando apenas mudar e mapear o código que roda a nível de kernel.\n",
    "\n",
    "Emulação: software executa instrução a instrução do arquivo.\n",
    "\n",
    "Um programa real possui uma fração que roda dentro do sistema operacional (operações de entrada e saída, por exemplo) e outras que usam a nível de usuário. Execução Direta com Binary Translation roda rapidamente a primeira, e faz uma tradução rápida para a segunda. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Machine Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VMM implementa a arquitetura completa do hardware em software.\n",
    "- O VMM segue as instruções da VM e atualiza o hardware emulado conforme necessário.\n",
    "- Pode lidar com todos os tipos de instruções, mas é muito lento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QEMU (Quick EMUlator) is an open-source emulator and virtualizer. It provides the ability to emulate entire hardware systems and supports a wide range of architectures. QEMU can emulate the hardware of various computer systems, including CPUs, memory, storage, network interfaces, and other peripherals. This allows software written for one architecture to run on a completely different architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Execução Direta com Trap-and-Emulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VMM (Ring 0)\n",
    "- Guest OS (Ring 1)\n",
    "- Guest Applications (Ring 3)\n",
    "\n",
    "Executar a maioria das instruções de convidado nativamente no hardware (assumindo que o sistema operacional convidado seja executado na mesma arquitetura do hardware real)\n",
    "\n",
    "Os aplicativos são executados no anel 3 (não é possível acessar a memória pertencente ao sistema operacional convidado (anel 1))\n",
    "\n",
    "O SO convidado é executado no anel 1 (não é possível acessar a memória pertencente ao VMM (anel 0))\n",
    "\n",
    "Não é possível permitir que o sistema operacional convidado execute instruções confidenciais diretamente!\n",
    "- Goldberg (1974)'s two classes of instructions:\n",
    "  - *privileged instructions*: those that trap when in user mode\n",
    "  - *sensitive instructions*: those that modify or depend on hardware configurations\n",
    "\n",
    "Quando o sistema operacional convidado executa uma instrução privilegiada, será interceptado para o VMM.\n",
    "\n",
    "Quando os aplicativos convidados geram uma interrupção de software, serão interceptados no VMM.\n",
    "\n",
    "Instrução privilegiada é executada no modo núcleo, só podem ser rodadas pelos OS. Se está no modo usuário, se provoca um desvio para o OS, através de um *trap*. \n",
    "\n",
    "*TRAP*: Ás vezes há causas que causam interrupção do fluxo normal de execução do processador, para que a execução seja desviada para um outro local (geralmente esse local é apontado por um vetor de interrupções, uma grande tabela que tem o número da interrupção que chegou como indexador).\n",
    "\n",
    "O x86 fez uma instrução sensível que não era privilegiada: certas situações que deveriam provocar a mudança do estado do processo sendo rodado pelo usuário deveria cair pro SO do usuário que tá rodando na MV. Mas isso não ocorre, por a instrução sensível é uma instrução normal no x86. Isso gerou problemas.\n",
    "\n",
    "O hypervisor ou gerenciado (monitor) de MV roda no nível 0 (de mais alta prioridade: capaz de executar tudo que tem direito).\n",
    "\n",
    "As aplicações do usuário rodam no nível 3.\n",
    "\n",
    "O OS guest roda no nível 1, pois não pode estar no nível 0 (se estivesse, poderia controlar o VMM, uma vez qeu teria acesso a tudo). Ao se rodar esse tipo de coisa, pode haver vários guest OSs; se poderia perturbar a vida dos outros guest OSs.\n",
    "\n",
    "Se todas as operações sensíveis são subconjunto das operações privilegiadas, não há problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trap and Emulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Goal: hand off sensitive operations to the VMM\n",
    "- Reality: privileged operations trap to VMM\n",
    "- VMM emulates the effect of privileged operations on virtual hardware provided to the guest OS\n",
    "- VMM controls how the VM interacts with physical hardware\n",
    "- VMM fools the guest OS into thinking that it runs at the highest privilege level\n",
    "- Performance implications\n",
    "  - Almost no overhead for non-privileged instructions\n",
    "  - Large overhead for privileged instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teorema de Popek e Goldberg: *Uma máquina pode ser virtualizada usando trap-and-emulate se toda instrução sensível for privilegiada*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução Direta com Tradução Binária"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VMM reescreve as instruções dinamicamente, para que as instruções não virtualizáveis possam capturar o VMM. \n",
    "\n",
    "É o principal ponto de venda da VMware.\n",
    "\n",
    "Dado que trap-and-emulate tem aqueles problemas de trap aquelas instruções. Nessa solução, as instruções são monitoradas para que instruções sensíveis são traduzidas.\n",
    "\n",
    "- Binary: Input is binary x86 code\n",
    "- Dynamic: Translation happens at runtime\n",
    "- On demand: Code is translated only when it is about to execute\n",
    "- System level: Rules set by x86 ISA, not higher-level ABIs\n",
    "- Subsetting: Output a safe subset of input full x86 instruction set\n",
    "- Adaptive: Translated code is adjusted according to guest behavior changes\n",
    "\n",
    "Garantir eficiência é um problema dessa solução.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução Direta com Hardware-Assisted Virtualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virtualização de CPU assistida por hardware (Intel VT-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dois novos modos de execução (ortogonais aos anéis de proteção)\n",
    "- Modo root VMX: igual ao x86 sem VT-x\n",
    "- Modo não root VMX: executa a VM; instruções sensíveis causam transição para o modo root, mesmo no anel 0\n",
    "\n",
    "Nova estrutura de hardware: VMCS (estrutura de controle de máquina virtual)\n",
    "- Um VMCS para um processador virtual\n",
    "- Configurado pelo VMM para determinar quais instruções confidenciais causam a saída da VM\n",
    "- Especifica o estado do SO convidado\n",
    "\n",
    "\n",
    "<img src=\"figs/aula02/vtx.png\" alt=\"Taxonomy of Virtualization\" style=\"width:50%;\"/>\n",
    "\n",
    "Sem o VT-x, o guest OS ficava no Ring 1; certas instruções do guest OS chamavam uma interrupção que caía no hypervisor; e outros códigos do guest OS rodavam direto em cima do hardware (Ring 3 indo direto pro hardware). Mas certas coisas rodando no guest OS e nas guest applications não chamavam o hypervisor.\n",
    "\n",
    "Com o VT-x, o hypervisor e o guest OS ficam no Ring 0. Mas não terá um excesso de acesso ao guest OS, pois ele entra no modo VMX non-root. O VMX dá acesso diferenciado para algumas coisas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMV-QEMU\n",
    "\n",
    "- QEMU (Userspace process): Works with binary translation if no hardware support; sets up guest VM memory as part of userspace process\n",
    "- KMV (kernel module): When invoked, KMV switches to VMX mode to run guest\n",
    "- CPU with VMX mode: CPU switches between VMX and non-VMX root modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O KMV é o necessário para se instalar uma MV, não precisa do QEMU. O QEMU, um emulador, costuma vir junto apesar de não ser necessário para se ter a MV. Mas o QEMU é muito bom para emular entrada-saída (disco, vídeo, terminal de console, rede); há até emulador de SSD. KVM também tem coisas input-output.\n",
    "\n",
    "<img src=\"figs/aula02/qemu.png\" style=\"width:50%;\"/>\n",
    "\n",
    "<img src=\"figs/aula02/qemu_kvm.png\" style=\"width:50%;\"/>\n",
    "\n",
    "<img src=\"figs/aula02/qemu_kvm2.png\" style=\"width:50%;\"/>\n",
    "\n",
    "- QEMU creates guest physical memory, one thread per VPCU\n",
    "- QEMU VCPU thread gives KVM_RUN command to KVM kernel module\n",
    "- KVM configures VM information in VMCS, launches guest OS in VMX mode\n",
    "- Guest OS runs natively on CPU until VM exit happens\n",
    "- Control returns to KVM/Host OS on VM exit\n",
    "- VM exits handled by KVM or QEMU\n",
    "- Host schedules QEMU like any other process, not aware of guest OS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBVIRT\n",
    "\n",
    "<img src=\"figs/aula02/libvirt.png\" style=\"width:50%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In emulation, the Virtual Machine Monitor (VMM) provides hardware simulation, making it independent of the underlying system hardware. This is because emulation simulates the entire hardware environment, allowing the guest system to run regardless of the host system's hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VirtualBox is an example of a Type-2 hypervisor, which runs on top of an existing operating system rather than directly on the hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação do Virtual Machine Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguindo o tutorial\n",
    "https://www.tecmint.com/install-qemu-kvm-ubuntu-create-virtual-machines/\n",
    "no meu PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alex@alex-inspiron:~$ egrep -c '(vmx|svm)' /proc/cpuinfo\n",
    "8\n",
    "\n",
    "Ou seja, há 8 cores disponíveis (mas pode haver hyperthreading). \n",
    "\n",
    "alex@alex-inspiron:~$ kvm-ok\n",
    "INFO: /dev/kvm exists\n",
    "KVM acceleration can be used\n",
    "\n",
    "/dev/kvm é a porta de entrada para o módulo KVM. Aí que o QEMU pede recursos\n",
    "\n",
    "alex@alex-inspiron:~$ sudo apt install qemu-kvm virt-manager virtinst libvirt-clients bridge-utils libvirt-daemon-system -y\n",
    "\n",
    "At this point, we have installed QEMU and all the essential virtualization packages. \n",
    "\n",
    "sudo systemctl enable --now libvirtd\n",
    "\n",
    "sudo systemctl start libvirtd\n",
    "\n",
    "alex@alex-inspiron:~$ sudo systemctl status libvirtd\n",
    "● libvirtd.service - Virtualization daemon\n",
    "     Loaded: loaded (/lib/systemd/system/libvirtd.service; enabled; vendor preset: enabled)\n",
    "     Active: active (running) since Wed 2024-06-26 19:34:17 -03; 13min ago\n",
    "TriggeredBy: ● libvirtd-ro.socket\n",
    "             ● libvirtd.socket\n",
    "             ● libvirtd-admin.socket\n",
    "       Docs: man:libvirtd(8)\n",
    "             https://libvirt.org\n",
    "   Main PID: 13661 (libvirtd)\n",
    "      Tasks: 21 (limit: 32768)\n",
    "     Memory: 10.7M\n",
    "        CPU: 651ms\n",
    "     CGroup: /system.slice/libvirtd.service\n",
    "             ├─13661 /usr/sbin/libvirtd\n",
    "             ├─13821 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvir>\n",
    "             └─13822 /usr/sbin/dnsmasq --conf-file=/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/lib/libvirt/libvir>\n",
    "jun 26 19:34:17 alex-inspiron systemd[1]: Started Virtualization daemon.\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq[13821]: started, version 2.90 cachesize 150\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq[13821]: compile time options: IPv6 GNU-getopt DBus no-UBus i18n IDN2 DHCP DHCPv6 no-Lua TFTP conntrack >\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq-dhcp[13821]: DHCP, IP range 192.168.122.2 -- 192.168.122.254, lease time 1h\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq-dhcp[13821]: DHCP, sockets bound exclusively to interface virbr0\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq[13821]: reading /etc/resolv.conf\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq[13821]: using nameserver 127.0.0.53#53\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq[13821]: read /etc/hosts - 8 names\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq[13821]: read /var/lib/libvirt/dnsmasq/default.addnhosts - 0 names\n",
    "jun 26 19:34:18 alex-inspiron dnsmasq-dhcp[13821]: read /var/lib/libvirt/dnsmasq/default.hostsfile\n",
    "\n",
    "From the output above, the libvirtd daemon is up and running as expected. \n",
    "\n",
    "sudo usermod -aG kvm $USER\n",
    "\n",
    "sudo usermod -aG libvirt $USER\n",
    "\n",
    "The next step is to launch the QEMU/KVM GUI tool which is the Virtual Machine Manager.\n",
    "\n",
    "sudo virt-manager\n",
    "\n",
    "Um novo programa \"Virtual Machine Manager\" pops up. From here, you can start creating and managing virtual machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalei o Ubuntu Server 22.0 nesse Virtual Machine Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Memory and CPU settings:\n",
    "Memory: 2048\n",
    "CPUs: 2\n",
    "Create a disk image for the virtual machine:\n",
    "15.0 GiB\n",
    "\n",
    "Network selection:\n",
    "NAT\n",
    "\n",
    "Com bridge, vai ter um novo endereço IP; assim, a máquina pode ser acessada do mundo externo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubuntu Server 22.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula02/cpu.png\" alt=\"IaaS, PaaS, and SaaS Comparison\" style=\"width:50%;\"/>\n",
    "\n",
    "#### Sysbench CPU Benchmark Results\n",
    "\n",
    "##### Test Configuration\n",
    "- **Sysbench Version**: 1.0.20 (using system LuaJIT 2.1.0-beta3)\n",
    "- **Number of Threads**: 1\n",
    "- **Prime Numbers Limit**: 10000\n",
    "\n",
    "##### CPU Speed\n",
    "- **Events Per Second**: 1049.97\n",
    "\n",
    "The CPU handled 1049.97 events per second, which indicates the performance of the CPU in processing the workload.\n",
    "\n",
    "##### General Statistics\n",
    "- **Total Time**: 10.0006 seconds\n",
    "- **Total Number of Events**: 10502\n",
    "\n",
    "The total time for the test was approximately 10 seconds. The CPU processed a total of 10502 events during the test.\n",
    "\n",
    "##### Latency (milliseconds)\n",
    "- **Minimum**: 0.94 ms\n",
    "- **Average**: 0.95 ms\n",
    "- **Maximum**: 3.18 ms\n",
    "- **95th Percentile**: 1.01 ms\n",
    "- **Sum**: 9990.28 ms\n",
    "\n",
    "##### Threads Fairness\n",
    "- **Events (avg/stddev)**: 10502.0000/0.00\n",
    "- **Execution Time (avg/stddev)**: 9.9903/0.00 seconds\n",
    "\n",
    "The average and standard deviation of events processed by the thread were 10502.0000 and 0.00, respectively, indicating consistent performance.\n",
    "\n",
    "The average execution time was 9.9903 seconds with no deviation, showing uniformity in execution time across the test.\n",
    "\n",
    "These results provide an overview of the CPU's performance under the given test conditions, highlighting its event processing capability and latency metrics.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"figs/aula02/memory.png\" alt=\"IaaS, PaaS, and SaaS Comparison\" style=\"width:50%;\"/>\n",
    "\n",
    "The memory test performed 44,148,636 operations, with an average rate of 4,414,078.59 operations per second.\n",
    "\n",
    "A total of 43,113.90 MiB of data was transferred, with an average transfer rate of 4,310.62 MiB/sec.\n",
    "\n",
    "These results provide an overview of the memory performance under the given test conditions, highlighting the operations per second and data transfer rates, along with latency metrics.\n",
    "\n",
    "The total time for the test was approximately 10 seconds. The CPU handled 44,148,636 events during the test.\n",
    "\n",
    "\n",
    "<img src=\"figs/aula02/fileio.png\" alt=\"IaaS, PaaS, and SaaS Comparison\" style=\"width:50%;\"/>\n",
    "\n",
    "The test performed 0 reads per second as it was a sequential write test. The test performed 979.05 writes per second. The test performed 1259.57 fsyncs per second.\n",
    "\n",
    "The read throughput was 0.00 MiB/s because the test did not involve reading operations. The write throughput was 15.30 MiB/s, indicating the rate at which data was written to the files.\n",
    "\n",
    "The average and standard deviation of events processed by the thread were 22,280.0000 and 0.00, respectively, indicating consistent performance. The average execution time was 9.9463 seconds with no deviation, showing uniformity in execution time across the test. These results provide an overview of the file I/O performance under the given test conditions, highlighting the write operations, throughput, and latency metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker e Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=Sc9XOSTjFcU\n",
    "\n",
    "1h41min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Máquinas virtuais são uma tecnologia-chave para a implementação da IAAS. Virtualização a nível de sistemas operacionais é importante para a implementação de PAAS; é uma virtualização mais leve e rápida.\n",
    "\n",
    "Essa virtualização a nível de sistemas operacionais não usa o conceito de máquinas virtuais (não é possível instalar o seu OS em cada sistema virtualizado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/container_x_vm.png\"  style=\"width:80%;\"/>\n",
    "\n",
    "Os containers compartilham o OS base, possuem diferentes conjuntos de bibliotecas, utilitários, sistemas de arquivos raiz, visualização da árvore de processes, rede, etc. As VMs possuem cópiad diferentes do próprio OS. Os containers exervem menos sobrecarga do que as VMs, mas também apresentam menos isolamento.\n",
    "\n",
    "Cada container acha que tem o OS só para ele. A máquina virtual acha que tem tudo pra ela (não só o OS, mas também hardware).\n",
    "\n",
    "Quando baixo uma imagem de um OS, não baixa o kernel junto (pode-se ter separados root file systems, libraries, utilities; mas não kernel); já uma máquina virtual tem seu próprio kernel. Numa máquina com containers, o kernel é compartilhado.\n",
    "\n",
    "In Unix-like operating systems, the user with ID 0 is known as the root user, who possesses the highest level of privileges and control over the system. The process with Process ID (PID) 1 is the initial process started by the kernel during the system boot sequence. This process, commonly known as \"init\" or \"systemd\" in modern Linux distributions, is responsible for mounting the root filesystem and initiating other essential system processes, thereby setting up the user space environment.\n",
    "\n",
    "From within a container, it is not possible to see the processes of another container. Containers isolate their own processes, hiding any processes created within them from other containers. This isolation ensures that each container operates independently and securely, maintaining a clear separation of processes between containers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Namespaces are a Linux kernel feature released in kernel version 2.6.24 in 2008. They provide processes with their own system view, thus isolating independent processes from each other. In other words, namespaces define the set of resources that a process can use (you cannot interact with something that you cannot see). At a high level, they allow fine-grain partitioning of global operating system resources such as mounting points, network stack and inter-process communication utilities. A powerful side of namespaces is that they limit access to system resources without the running process being aware of the limitations. In typical Linux fashion they are represented as files under the `/proc/<pid>/ns` directory (these files allow you to inspect and manage the namespaces) ( `<pid>` represents the process id).\n",
    "\n",
    "Think of them as creating mini-systems within the larger operating system. Each of these mini-systems, or namespaces, has its own set of resources, like files, network interfaces, and communication tools. This means that processes running in different namespaces are kept separate and can't see or interfere with each other’s resources. A process in one namespace doesn't even know about the existence of resources in another namespace. \n",
    "\n",
    "The processes run as if they have full access to the system, but in reality, their view is limited to what the namespace allows. This is particularly useful for creating secure and isolated environments for applications.\n",
    "\n",
    "Namespaces provide a way to create isolated environments within the same operating system, enhancing security and resource management, and they are crucial for technologies like containers, which rely on this isolation to function effectively.\n",
    "\n",
    "<img src=\"figs/aula03/namespace1.png\"  style=\"width:50%;\"/>\n",
    "\n",
    "Containers on Linux utilize the namespaces provided by the Linux kernel. On Linux, the containers are running as normal processes which share the same kernel as other processes. On Windows or Mac, one virtual machine is provided first. All the containers are running inside the virtual machine.\n",
    "\n",
    "In computer science, everything can be represented by an object, including network devices, processes, threads, PID numbers, routing tables, file systems, etc. If we define a namespace object, then put the network device objects as a member of this namespace object, then we are able to restrict the scope of network devices to a certain namespace. The same goes for other objects.\n",
    "\n",
    "Each process on Linux has a unique PID number. The processes are in a tree structure. When one process creates another, it becomes the parent of the other process. The first process on Linux is the init process which has PID=1.\n",
    "\n",
    "<img src=\"figs/aula03/init.png\"  style=\"width:35%;\"/>\n",
    "\n",
    "Processes can create a new `pid_namespace` and put their child processes in the new PID namespace. The new `pid_namespace` becomes a child the parent pid_namespace. The PID number in a new `pid_namespace` starts with 1.\n",
    "\n",
    "<img src=\"figs/aula03/init2.png\"  style=\"width:35%;\"/>\n",
    "\n",
    "When a process inside a `pid_namespace` sees itself, it sees its subjective PID from within its own `pid_namespace`. However, when another process outside of the `pid_namespace` sees it, the other process uses its own `pid_namespace` as reference. It sees a different PID number.\n",
    "\n",
    "In the picture, we have a three-layer PID namespace hierarchy. The processes in the `child-namespace` see themselves having PID 1,2,3. However, processes from `init-namespace` see the processes in the `child-namespace` having PID 4,5,6.\n",
    "\n",
    "Processes in the `grandchild-namespace` see themselves having PID 1,2,3. However, the processes from `child-namespace` see them having PID 4,5,6. The processes from `init-namespace` see them having PID 7,8,9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Mechanisms in the Linux Kernel on which Containers are Built:\n",
    "\n",
    "**Namespaces:**  \n",
    "Namespaces provide an isolated view of a global resource (such as the root filesystem) for a set of processes. Processes within a namespace see only their portion of the global resource. This isolation ensures that processes in different namespaces cannot see or interact with each other's resources.\n",
    "\n",
    "**Cgroups:**  \n",
    "Cgroups (Control Groups) are a way to define resource limits for a group of processes. They allow the allocation and restriction of resources like CPU time, memory, disk I/O, etc., ensuring that no single process can exhaust system resources.\n",
    "\n",
    "Together, namespaces and cgroups allow us to isolate a set of processes into a \"bubble\" and set resource limits for them. This combination ensures both isolation and resource management for processes.\n",
    "\n",
    "Implementations of containers like LXC and Docker leverage these mechanisms to build container abstractions. LXC is a general-purpose container, while Docker is optimized for single applications.\n",
    "\n",
    "Frameworks like Docker Swarm or Kubernetes help manage multiple containers across hosts, providing features like automatic scaling, lifecycle management, and more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namespaces: group of Processes with an Isolated/Sliced View of a Global Resource\n",
    "\n",
    "In Linux, all processes start in the default namespace. Through system calls, new namespaces can be created, and processes can be assigned to these namespaces.\n",
    "\n",
    "#### Which Resources Can Be Isolated?\n",
    "\n",
    "1. **Mount Namespace:** Isolates the filesystem mount points seen by a group of processes. The `mount()` and `umount()` system calls affect only the processes within this namespace.\n",
    "\n",
    "2. **PID Namespace:** Isolates the PID number space seen by processes. For example, the first process in a new PID namespace has a PID of 1.\n",
    "\n",
    "3. **Network Namespace:** Isolates network resources like IP addresses, routing tables, and port numbers. For example, processes in different network namespaces can reuse the same port numbers.\n",
    "\n",
    "4. **UTS Namespace:** Isolates the hostname and NIS domain name.\n",
    "\n",
    "5. **User Namespace:** Isolates the UID/GID number space. For example, a process can have a UID of 0 (root) within a namespace but have no privileges outside that namespace. UID mappings between the parent and child namespaces are specified.\n",
    "\n",
    "6. **IPC Namespace:** Isolates POSIX message queues and other IPC resources.\n",
    "\n",
    "\n",
    "The UTS (UNIX Time-Sharing) namespace allows you to modify the hostname and domain name of your machine. Each process can have a different hostname and domain name, which can be modified as needed. This feature provides isolation at the system identity level, ensuring that each process or container can operate with its own unique system identifiers.\n",
    "\n",
    "Namespace is more powerful than `chroot()`, which isolates only the filesystem root.\n",
    "\n",
    "The filesystem root in Linux, denoted by \"/\", is the topmost directory in the hierarchy of the filesystem. It serves as the starting point from which all other directories and files branch out. When you list the contents of the root directory, you typically see system-critical directories like `/bin`, `/etc`, `/home`, `/lib`, `/var`, and more. This root directory is fundamental to the organization and structure of the filesystem, acting as the anchor point for all other files and directories on the system.\n",
    "\n",
    "The UID (User ID) and GID (Group ID) number space in Linux refer to the unique identifiers assigned to each user and group, respectively. Every user on a Linux system has a unique UID, and every group has a unique GID. These IDs are used by the system to determine ownership and permissions for files and processes. The UID/GID number space is essentially the range of possible values for these identifiers, allowing the system to manage and distinguish between different users and groups efficiently. \n",
    "\n",
    "For example, the root user typically has a UID of 0, which grants it superuser privileges. Other users will have different UIDs, ensuring that they have access only to their own files and resources. Similarly, groups are identified by GIDs, which help manage permissions and access control for multiple users collectively.\n",
    "\n",
    "IPC stands for Inter-Process Communication. IPC resources in Linux are mechanisms that allow processes to communicate and synchronize their actions. Common IPC methods include message queues, semaphores, shared memory, and sockets. These resources are crucial for enabling different processes to work together by exchanging data or signaling events.\n",
    "\n",
    "POSIX stands for Portable Operating System Interface. It is a family of standards specified by the IEEE for maintaining compatibility between operating systems. POSIX defines APIs and interfaces for system calls, file handling, IPC, and more, ensuring that software developed on one compliant system can run on another with minimal modification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namespaces are a more powerful and flexible mechanism for isolation in Unix-like operating systems compared to `chroot()`. While `chroot()` only isolates the filesystem root, essentially changing the apparent root directory for a process and its children, namespaces provide isolation across multiple aspects of the operating system environment. \n",
    "\n",
    "Namespaces can isolate:\n",
    "\n",
    "1. **Process IDs (PID namespace)**: Each container or process group can have its own PID namespace, allowing processes to have the same PID in different containers without conflict.\n",
    "\n",
    "2. **Mount points (Mount namespace)**: This allows each container to have its own filesystem structure, independent of the host or other containers.\n",
    "\n",
    "3. **Network interfaces (Network namespace)**: Each container can have its own network interfaces, IP addresses, routing tables, and firewall rules.\n",
    "\n",
    "4. **Interprocess Communication (IPC namespace)**: This isolates communication mechanisms like message queues and semaphores, so they are not shared between containers.\n",
    "\n",
    "5. **UTS (UNIX Time-Sharing namespace)**: This allows each container to have its own hostname and domain name, providing isolation at the system identity level.\n",
    "\n",
    "6. **User IDs (User namespace)**: This enables each container to have its own set of user and group IDs, enhancing security by allowing processes to run as non-root users within the container even if they are root on the host.\n",
    "\n",
    "7. **Control groups (Cgroups namespace)**: This provides resource management and isolation for groups of processes, controlling CPU, memory, disk I/O, and network usage.\n",
    "\n",
    "By isolating these various aspects, namespaces provide a much more comprehensive and robust form of isolation compared to `chroot()`, which only limits the view of the filesystem. This makes namespaces ideal for creating containers and other isolated environments, enabling multiple isolated instances to run on a single host system without interfering with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namespaces are the essence of containerization and Docker, providing the foundational isolation required for containers. However, namespaces alone are not sufficient for Docker to function effectively. In addition to namespaces, Docker relies on other technologies such as cgroups for resource management, union file systems for efficient storage, and a robust networking stack to enable communication between containers and the outside world. These additional components work together to create the complete containerization platform that Docker provides, ensuring containers are isolated, resource-efficient, and easy to manage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Namespaces API\n",
    "\n",
    "System Calls Related to Namespaces:\n",
    "\n",
    "1. **clone()**:\n",
    "    - Used to create a new process and place it in a new namespace. This is a more general version of `fork()`.\n",
    "    - Example:\n",
    "      ```c\n",
    "      childPID = clone(childFunc, childStack, flags, arg);\n",
    "      ```\n",
    "    - The `flags` specify what should be shared with the parent and what should be created anew for the child (including virtual memory, file descriptors, namespaces, etc.).\n",
    "\n",
    "2. **setns()**:\n",
    "    - Allows a process to join an existing namespace. \n",
    "    - The arguments specify which namespace and its type.\n",
    "\n",
    "3. **unshare()**:\n",
    "    - Creates a new namespace and places the calling process in it. \n",
    "    - The `flags` indicate which namespace to create. \n",
    "    - Forking a process and calling `unshare()` is equivalent to `clone()`.\n",
    "\n",
    "- Once a process is in a namespace, it can open a shell and perform other useful tasks within that namespace.\n",
    "- By default, forked children of a process belong to the parent's namespace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To effectively use namespaces in Linux, there are three crucial system calls: `clone`, `setns`, and `unshare`.\n",
    "\n",
    "1. **clone**: This system call is a more versatile version of `fork`. It creates a new process and can place it into a new namespace. With `clone`, you can specify which namespaces (e.g., PID, network, mount, etc.) should be shared with the parent process and which should be created anew, allowing for fine-grained control over process isolation.\n",
    "\n",
    "2. **setns**: This system call allows an existing process to join an already established namespace. Essentially, it instructs the process to enter a specified namespace, such as a PID, network, or mount namespace. The target namespace must exist beforehand, and this call changes the namespace context of the process to that of the specified namespace.\n",
    "\n",
    "3. **unshare**: This system call enables a process to disassociate from its current namespace and create a new one. When a process calls `unshare`, it breaks away from its existing namespace, creating a new namespace for specified resources. This allows the process to have a separate environment for those resources. If a process forks and then calls `unshare`, it is effectively the same as using `clone` to create a new namespace from the start.\n",
    "\n",
    "These system calls are fundamental for creating isolated environments, which are essential for containerization. They enable processes to operate in distinct namespaces, ensuring isolation and independence from the host system and other containers.\n",
    "\n",
    "Each application you run on your computer, like a web browser, text editor, or game, is a process. For example, when you open a web browser, the operating system creates a process to run it. Operating systems also run many background processes that manage hardware, perform scheduled tasks, and provide various system services. These include processes like `init`, which is the first process started by the kernel and remains running to manage system startup and shutdown.\n",
    "\n",
    "The `fork` system call in Unix-like operating systems is used to create a new process by duplicating the existing process. The new process is referred to as the child process, while the original process is called the parent process. Here's a more detailed explanation:\n",
    "\n",
    "When a process calls `fork`, the operating system creates a new process that is an exact copy of the parent process. This includes a copy of the parent’s memory, file descriptors, and execution state.\n",
    "The `fork` call returns twice: once in the parent process and once in the child process.\n",
    "- In the parent process, `fork` returns the Process ID (PID) of the newly created child process.\n",
    "- In the child process, `fork` returns 0.\n",
    "\n",
    "After the `fork` call, both the parent and child processes continue executing from the point where the `fork` call was made. They have separate address spaces, meaning changes in the memory of one process do not affect the other.\n",
    "\n",
    "`fork` is commonly used to perform parallel execution. For example, a server might `fork` a new process to handle each incoming client request, allowing the server to handle multiple clients simultaneously.\n",
    "\n",
    "Each process runs independently, providing isolation. This is crucial for tasks that require a high degree of separation between different operations.\n",
    "\n",
    "Modern operating systems use a technique called copy-on-write (COW) for `fork`. This means that the parent and child processes share the same memory pages initially, and pages are copied only when they are modified, which makes `fork` more efficient. Since `fork` creates two processes running concurrently, proper synchronization mechanisms (like semaphores or mutexes) may be needed to coordinate shared resources between parent and child processes. The `fork` system call is a fundamental mechanism in Unix-like operating systems for process creation and is the basis for process control and management in these systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Namespace handles\n",
    "\n",
    "The directory `/proc/PID/ns` of a process contains information about which namespace a process belongs to. These are symbolic links pointing to the inode of that namespace (\"handle\").\n",
    "\n",
    "Example:\n",
    "```sh\n",
    "$ ls -l /proc/$$/ns\n",
    "# $$ is replaced by shell's PID\n",
    "total 0\n",
    "lrwxrwxrwx. 1 user user 0 Jan  8 04:12 ipc  -> ipc:[4026531839]\n",
    "lrwxrwxrwx. 1 user user 0 Jan  8 04:12 mnt  -> mnt:[4026531840]\n",
    "lrwxrwxrwx. 1 user user 0 Jan  8 04:12 net  -> net:[4026531956]\n",
    "lrwxrwxrwx. 1 user user 0 Jan  8 04:12 pid  -> pid:[402653186]\n",
    "lrwxrwxrwx. 1 user user 0 Jan  8 04:12 user -> user:[4026531837]\n",
    "lrwxrwxrwx. 1 user user 0 Jan  8 04:12 uts  -> uts:[4026531838]\n",
    "```\n",
    "\n",
    "- The namespace identifier can be used in system calls (for example, as an argument to `setns`).\n",
    "- Processes in the same namespace will have the same identifier. A new identifier will be created when a new namespace is created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PID Namespaces (1)\n",
    "\n",
    "- **The first process to be created in a new PID namespace** will have `PID=1` and will act as the init process in that namespace.\n",
    "    - This process will reap orphans in this namespace.\n",
    "\n",
    "- **Processes in a PID namespace** get a separate PID number space.\n",
    "    - The child of the init process gets `PID=2` onwards.\n",
    "\n",
    "- **A process can see all other processes in its own or nested namespaces**, but not in its parent namespace.\n",
    "    - Example:\n",
    "        - P2 and P3 are not aware of P1 (parent PID of P2 = 0).\n",
    "        - P1 can see P2 and P3 in its namespace (with different PIDs).\n",
    "        - P2=P2' (just different PIDs in different namespaces).\n",
    "\n",
    "<img src=\"figs/aula03/pid1.png\"  style=\"width:20%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PID Namespaces (2)\n",
    "\n",
    "- **First process in a namespace acts as init and has special privileges**:\n",
    "    - Other processes in the namespace cannot kill it.\n",
    "    - If the init process dies, the namespace is terminated.\n",
    "    - However, the parent process can kill the init process in the parent namespace.\n",
    "\n",
    "- **Who reaps whom?**:\n",
    "    - The init process is reaped by the parent in the parent namespace.\n",
    "    - Other child processes are reaped by their parent in the same namespace.\n",
    "    - Any orphan process in a namespace is reaped by the init process of that namespace.\n",
    "\n",
    "<img src=\"figs/aula03/pid2.png\"  style=\"width:20%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PID Namespaces (3)\n",
    "\n",
    "Namespace-related system calls have slightly different behavior with PID namespaces alone. `clone()` creates a new namespace for the child as expected. However, `setns()` and `unshare()` do not change the PID namespace of the calling process. Instead, the child processes will begin in a new PID namespace.\n",
    "\n",
    "Why this difference? If the namespace changes, the PID returned by `getpid()` will also change. However, many programs assume that `getpid()` returns the same value throughout the life of the process. `getpid()` returns the PID in the namespace the process resides in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Namespaces\n",
    "\n",
    "When a Linux system boots up, it starts with an initial filesystem structure that contains the necessary directories and files for the operating system to function. This initial structure can be extended by mounting additional filesystems. For instance, a USB drive (pen drive) has its own independent directory structure. To access the contents of a USB drive in Linux, you need to mount it to a directory within the existing Linux filesystem. This is done using the mount command, which integrates the USB drive’s filesystem with the Linux filesystem.\n",
    "\n",
    "Once the USB drive is mounted, its directory structure becomes part of the overall filesystem hierarchy of the system. This integration allows users to access and interact with files on the USB drive as if they were part of the original filesystem. Consequently, the new filesystem is a composite of the initial filesystem plus any additional filesystems that have been mounted, enabling seamless access and management of multiple storage devices within a unified directory structure.\n",
    "\n",
    "- The root filesystem seen by a process is constructed from a set of mount points (syscalls `mount()` and `umount()`).\n",
    "\n",
    "- The new mount namespace can have a new set of mount points:\n",
    "    - This provides a new view of the root filesystem.\n",
    "\n",
    "- Mount points can be shared or private:\n",
    "    - Shared mount points are propagated to all namespaces, while private ones are not.\n",
    "    - If the parent makes all its mount points private and clones the child in the new mount namespace, the child will start with an empty root filesystem.\n",
    "\n",
    "- Use mount namespaces to create a customized root filesystem for each container using a base `rootfs` image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Namespaces and ps\n",
    "\n",
    "- **How does `ps` work?**:\n",
    "    - Linux has a special `procfs`, where the kernel populates information about processes.\n",
    "    - Reading `/proc/PID/...` does not read a file from disk but fetches information from the operating system.\n",
    "    - `procfs` is mounted at root as a special type of filesystem.\n",
    "\n",
    "- P1 clones P2 to be in the new PID namespace but uses the old mount namespace. We open a shell in the new PID namespace and run `ps`. We still see all the processes from the parent namespace. Why?:\n",
    "    - The `ps` command is still using `procfs` from the parent mount namespace.\n",
    "\n",
    "- **How to make `ps` work correctly inside a PID namespace?**:\n",
    "    - Place P2 in the new mount namespace and mount a new `procfs` at the root.\n",
    "    - The new `procfs` at the mount point is different from the parent's `procfs`.\n",
    "    - `ps` will now show only processes in this PID + mount namespace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Namespaces (1)\n",
    "\n",
    "- A network namespace can be created by cloning a process into a new namespace or simply via the command line:\n",
    "    ```sh\n",
    "    # ip netns add netns1\n",
    "    ```\n",
    "\n",
    "- The list of network namespaces can be viewed in `/var/run/netns`. You can use `setns()` to join an existing namespace.\n",
    "\n",
    "- The command `ip netns exec` can be used to execute commands inside the network namespace, for example, to list all IP links:\n",
    "    ```sh\n",
    "    # ip netns exec netns1 ip link list\n",
    "    1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT\n",
    "       link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Namespaces (2)\n",
    "\n",
    "- Any new network namespace only has a loopback interface. How to communicate with the rest of the network?\n",
    "\n",
    "- Create a virtual Ethernet link (veth pair) to connect the parent namespace to the new child namespace:\n",
    "    - Assign endpoints to two different namespaces.\n",
    "    - Assign IP addresses to both endpoints.\n",
    "    - Communicate through this link with the parent namespace.\n",
    "    - Configure bridge/NAT to connect to a broader Internet.\n",
    "\n",
    "<img src=\"figs/aula03/network_namespaces2.png\"  style=\"width:40%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cgroups\n",
    "\n",
    "Namespaces provide the necessary isolation for containers, but without proper resource control, this isolation is ineffective. A machine has limited resources, such as CPU cores and memory. If processes or containers request more resources than available, it can cause system instability and performance issues.\n",
    "\n",
    "To prevent this, resource limiters are essential for each container. For example, you might create a new namespace but want to restrict it to use only a maximum of two CPU cores. These limitations ensure that each container operates within its designated resource boundaries, preventing resource contention and ensuring stable and efficient performance across the system.\n",
    "\n",
    "By combining namespaces for isolation with resource control mechanisms, such as cgroups, you can effectively manage and allocate system resources, maintaining balance and preventing any single container from monopolizing the available resources.\n",
    "\n",
    "- **Cgroup (Control Groups)**: A Linux kernel feature that limits, accounts for, and isolates the resource usage of a collection of processes.\n",
    "\n",
    "- **cgroups-v1**:\n",
    "    - Added to the Linux kernel initially by Google engineers Paul Menage and Rohit Seth in 2006 and called process containers.\n",
    "    - Appeared in the official kernel 2.6.24 in 2008 and was renamed to cgroups-v1 to avoid confusion with other entities.\n",
    "\n",
    "- **cgroups-v2**:\n",
    "    - Development and maintenance were then passed to Tejun Heo, who rewrote and reassigned cgroups starting in 2013.\n",
    "    - This rewrite is now called cgroups-v2 and its documentation appeared in Linux 4.5 on March 14, 2016.\n",
    "\n",
    "Namespaces allow us to isolate processes in a slice with respect to many resources: mount points, PID/UID number space, network endpoints, etc. Cgroups allow us to assign resource limits to a group of processes:\n",
    "- Divide processes into groups and subgroups hierarchically.\n",
    "- Assign resource limits to processes in each group/subgroup.\n",
    "\n",
    "What resources can be limited?\n",
    "- CPU, memory, I/O, CPU sets (which process can be executed on which CPU core), and so on.\n",
    "- Specify what fraction of a resource can be used by each group of processes.\n",
    "\n",
    "Creates separate hierarchies for each resource, or a combined hierarchy for multiple resources together.\n",
    "\n",
    "<img src=\"figs/aula03/cgroups.png\"  style=\"width:40%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Cgroups\n",
    "\n",
    "Creating cgroups does not involve any new system calls; it is managed through the filesystem. A special cgroup filesystem is mounted at `/sys/fs/cgroup`. Within this filesystem, directories and subdirectories are created for different resources and different classes of users. \n",
    "\n",
    "To create a cgroup, you write the PID of the \"founding parent\" task into the tasks file. This ensures that all child processes of this task will also be in the same cgroup. For example, to assign a process with `browser_pid` to a cgroup, you would use the command:\n",
    "```sh\n",
    "# echo browser_pid > /sys/fs/cgroup/<restype>/<userclass>/tasks\n",
    "```\n",
    "\n",
    "Tasks can be assigned to leaf nodes in the hierarchy. If tasks are not explicitly placed into any hierarchy, they will belong to the default cgroup of the parent. This hierarchical structure allows for organized and efficient resource management, as each task or group of tasks can be limited and accounted for in terms of resource usage such as CPU, memory, and I/O. By managing these resources at the cgroup level, system administrators can ensure that no single process or group of processes can monopolize system resources, thereby maintaining overall system stability and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Create a Container?\n",
    "\n",
    "To create a container, you first need to logically separate its environment using namespace tools. Namespaces provide the isolation necessary for the container's processes, network, and filesystem. After establishing this isolation, you then use cgroups to customize and manage the container's resource usage. Cgroups allow you to set limits on resources such as CPU, memory, and I/O to ensure that each container operates within its designated boundaries. Additionally, tools like `chroot` or `pivot_root` are used to set up a new root filesystem for the container. These tools help create an isolated filesystem environment within the container, separate from the host system's filesystem. Some experts argue that containers don't truly exist because they rely on existing system resources to restrict process access. Essentially, containers mask and manipulate the environment to achieve the desired isolation and resource management, rather than being entirely separate entities.\n",
    "\n",
    "Suppose you want to run an application or shell in a container. How would you do it?\n",
    "\n",
    "First, create separate namespaces for isolation. This includes creating namespaces for PID, mount points, network, and other necessary resources. These namespaces ensure that the process running inside the container is isolated from the host system and other containers.\n",
    "\n",
    "Next, create a root filesystem compatible with the CPU's ISA (Instruction Set Architecture) and the operating system's binaries. This root filesystem should contain all the utilities, binaries, and configuration files necessary to run the application.\n",
    "\n",
    "After setting up the root filesystem, a process enters the namespaces, mounts the root filesystem (rootfs), registers itself in the cgroups, and then executes the desired application or shell. This setup ensures that the application or shell runs in a fully isolated environment, effectively creating a \"container.\"\n",
    "\n",
    "By following these steps, you can successfully create and run applications in containers, leveraging the isolation and resource management features provided by namespaces and cgroups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container Frameworks\n",
    "\n",
    "LXC e Docker são duas soluções comerciais. LXC é uma virtual machine leve. Docker é mais amplo, permite desenvolver aplicações inteiras.\n",
    "\n",
    "Existing container frameworks, such as LXC and Docker, automatically handle the configuration of namespaces and cgroups, simplifying the process of container creation and management.\n",
    "\n",
    "**LXC** (Linux Containers) provide a lightweight virtual machine-like environment. LXC containers use the standard shell interface of the operating system and leverage namespaces and cgroups to ensure isolation and resource management.\n",
    "\n",
    "**Docker** containers are optimized for running a single application. The Docker configuration file specifies the base root filesystem along with all the necessary utilities to run a specific application. Docker runs the application in an isolated container environment, making it easy to package an application and all its dependencies and run it anywhere.\n",
    "\n",
    "By using these frameworks, developers and system administrators can create and manage containers efficiently, without manually configuring the underlying namespaces and cgroups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container Orchestration Frameworks\n",
    "\n",
    "Kubernetes pode rodar com o docker ou com outras soluções de containers.\n",
    "\n",
    "**Docker Swarm** and **Kubernetes** are frameworks designed to manage multiple containers across various hosts. These frameworks handle the orchestration of containers, ensuring that they run efficiently and can scale as needed.\n",
    "\n",
    "**Kubernetes** is a popular container orchestration framework. It operates across multiple <span style=\"color:green;\">physical machines (\"nodes\")</span>, each containing multiple \"pods\". <span style=\"color:yellow;\">A pod consists of one or more containers sharing the same network namespace and IP address</span>.\n",
    "\n",
    "Pods are typically layers of a multi-tier application (e.g., \"frontend\", \"backend\", \"database\", \"web server\"). Kubernetes manages these nodes and pods, for instance, by instantiating pods on free nodes, automatically scaling pods when the load increases, and restarting pods when they crash.\n",
    "\n",
    "Kubernetes facilitates the efficient and scalable deployment of containerized applications, ensuring high availability and resource optimization across a cluster of nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo\n",
    "\n",
    "Os containers fornecem isolamento leve com menor sobrecarga, uma vez que o OS não é reinstalado. Eles compartilham o mesmo binário do kernel, mas possuem sistemas de arquivos raiz diferentes. Em cima de um kernel compartilhado, há os utilitários básicos e as bibliotecas necessárias para a sua aplicação rodar. \n",
    "\n",
    "Containers provide lightweight isolation with minimal overhead. Unlike traditional virtual machines, containers share the same kernel binary but have different root filesystems, which include utilities and configurations on top of the kernel.\n",
    "\n",
    "Containers are implemented using two Linux primitives: **namespaces** and **cgroups**. Namespaces provide isolation, ensuring that the containerized processes do not interfere with each other or the host system. Cgroups are used to enforce resource limits, ensuring that each container gets its fair share of CPU, memory, and I/O resources.\n",
    "\n",
    "Frameworks like Docker, LXC, and Kubernetes build on these primitives to offer additional functionalities, such as simplified container management, orchestration, and scaling across multiple hosts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker\n",
    "\n",
    "|                   | Packaged Software | IAAS      | PAAS     | SAAS     | \n",
    "|-------------------|-------------------|-----------|----------|----------|\n",
    "|    Applications   |    x              |    x     |    x     |    ✓     |\n",
    "|    Data           |    x              |    x     |    x     |    ✓     |\n",
    "|    Runtime        |    x              |    x     |    ✓     |    ✓     |\n",
    "|    Middleware     |    x              |    x     |    ✓     |    ✓     |\n",
    "|    OS             |    x              |    x     |    ✓     |    ✓     |\n",
    "|    Virtualization |    x              |    ✓     |    ✓     |    ✓     |\n",
    "|    Servers        |    x              |    ✓     |    ✓     |    ✓     |\n",
    "|    Storage        |    x              |    ✓     |    ✓     |    ✓     |\n",
    "|    Networking     |    x              |    ✓     |    ✓     |    ✓     |\n",
    "\n",
    "✓ : managed by vendor ______ x : managed by user\n",
    "\n",
    "Docker is PAAS.\n",
    "    \n",
    "VMWare, KVM and VBox are IAAS.\n",
    "\n",
    "Middleware is software that provides common services and capabilities to applications outside of what's offered by the operating system. It enables communication and data management for distributed applications. Middleware essentially acts as a bridge between different software applications or between an application and the network. Some common functions of middleware include:\n",
    "- **Message Oriented Middleware (MOM)**: Facilitates communication between different systems using messaging queues.\n",
    "- **Database Middleware**: Connects applications to databases, enabling database access and management.\n",
    "- **Application Servers**: Provides an environment for running and managing applications.\n",
    "- **Web Servers**: Handles HTTP requests and responses, serving web pages to users.\n",
    "- **Transaction Monitors**: Manages transactions to ensure data integrity across distributed systems.\n",
    "\n",
    "\n",
    "A Docker image is a file used to execute code in a Docker container. Docker images act as a set of instructions to build a Docker container, such as a template. Docker images also act as the starting point when using Docker.\n",
    "\n",
    "A Docker image contains application code, libraries, tools, dependencies, and other files needed to make an application run. When a user runs an image, it can become one or many instances of a container.\n",
    "\n",
    "A Docker image has many layers. Each image includes everything needed to configure a container environment, including system libraries, tools, dependencies, and other files. The parts of an image include the following:\n",
    "\n",
    "- **Base image**: The user can build this first layer entirely from scratch with the build command. A base image functions as the initial empty layer, facilitating the construction of Docker images from the ground up. While providing full control over image contents, base images are generally tailored for users with advanced Docker skills.\n",
    "\n",
    "- **Parent image**: As an alternative to a base image, a parent image can be the first layer in a Docker image. It's a reused image that serves as a foundation for all other layers. A standard parent image typically consists of a bare-bones Linux distribution or comes with an installed service, such as a content management system or database management system.\n",
    "\n",
    "- **Layers**: Layers are added to the base image using code that enables it to run in a container. Each layer of a Docker image is viewable under `/var/lib/docker/aufs/diff` or via the Docker history command in the command-line interface (CLI). Docker's default status is to show all top-layer images, including repository, tags, and file sizes. Intermediate layers are cached, making top layers easier to view. Docker storage drives manage the image layer contents.\n",
    "\n",
    "- **Container layer**: A Docker image creates not only a new container but also a writable or container layer. This layer hosts changes made to the running container, and it stores newly written and deleted files as well as changes to existing files. This layer is also used to customize containers.\n",
    "\n",
    "A Dockerfile is a text file that contains instructions for the Docker daemon to use when building a container image. It provides information on the commands to run, files to copy, startup command, and more.\n",
    "\n",
    "Dockerfiles can be used to create automated builds that execute several command-line instructions in succession. They can also enable greater flexibility and portability of business applications. For example, IT organizations can use Dockerfiles to package applications and their dependencies in a virtual container that can run on premises, in public or private clouds, or on bare metal.\n",
    "\n",
    "Docker supports over 15 different instructions in Dockerfiles, including:\n",
    "\n",
    "- **FROM**: Refers to an existing image as the base for your build.\n",
    "- **COPY**: Adds files and folders to your image's filesystem.\n",
    "- **ENV**: Sets environment variables that will be available within your containers.\n",
    "- **RUN**: Executes commands within the container at build time.\n",
    "- **USER**: Changes the current directory.\n",
    "- **ADD**: Copies files and directories to the image and creates a new layer.\n",
    "- **CMD**: Sets default arguments for container start.\n",
    "- **ENTRYPOINT**: Sets default command for container start.\n",
    "- **EXPOSE**: Defines port assignments for the running container.\n",
    "- **VOLUME**: Includes a directory in the image as a volume when starting the container in the host system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/docker_namespaces.png\"  style=\"width:40%;\"/>\n",
    "\n",
    "Usamos cgroups e namespaces pra prover um ambiente seguro e isolado para cada um dos containers. Cada container foi engendrado para que se possa colocar 1 processo e os file systems e bibliotecas. Tudo rodando em cima de um kernel de um OS. \n",
    "\n",
    "A ideia é, dentro de uma certa máquina (host), se tem vários containers compartilhando o hardware e OS hospedeiro. Em cima desse hardware e desse OS hospedeiro se colocam vários containers, cada um tendo os complementos do OS necessários para rodar os serviços.\n",
    "\n",
    "Esse serviços se comunicam para poder satisfazer as necessidades da aplicação.\n",
    "\n",
    "Filesystem namespaces allow processes to have their own view of the filesystem hierarchy. This is an important feature in containerization, as it helps isolate processes from each other. Each namespace can have its own filesystem structure, which may include mounts, directories, and files.\n",
    "\n",
    "**Host Filesystem (Host FS):**\n",
    "- Represents the filesystem structure of the host machine. It contains various directories and files that are accessible to processes running on the host.\n",
    "\n",
    "**FS Namespace 1:**\n",
    "- Contains Process A.\n",
    "- Process A has its own local filesystem (Local FS), which can be a subset or a customized view of the host filesystem. This local filesystem is isolated from the host and other namespaces.\n",
    "**FS Namespace 2:**\n",
    "- Contains Process B.\n",
    "- Similar to Process A, Process B has its own isolated local filesystem.\n",
    "\n",
    "Each process operates within its own namespace, providing a level of isolation. This means that Process A cannot directly access the filesystem of Process B and vice versa. The red arrow in the image suggests that the local filesystems of the namespaces (FS Namespace 1 and FS Namespace 2) can map to directories or files within the host filesystem. This is typically done using mount points. By isolating filesystems, each process can operate independently without affecting others. This enhances security and stability, as changes in one namespace do not impact others.\n",
    "\n",
    "Each Docker container runs in its own filesystem namespace. This isolation ensures that the processes within the container have a limited and controlled view of the filesystem, which is critical for security and dependency management. When you mount volumes in Docker, you are essentially mapping directories from the host filesystem into the container's filesystem namespace. This allows containers to share data with the host or with other containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/namespaces_pid.png\"  style=\"width:40%;\"/>\n",
    "\n",
    "PID namespaces are a key feature in containerization that isolate the process ID number space, allowing processes inside containers to have their own set of PIDs, which are independent from those on the host system. Each container has its own PID namespace, meaning processes inside a container see a separate PID namespace from the host and other containers. This ensures that each container has its own isolated set of PIDs.\n",
    "\n",
    "The parent PID namespace is the host's namespace, and child namespaces are created for each container. This hierarchy allows the host to manage container processes while keeping them isolated from each other.\n",
    "\n",
    "Processes within containers can have PID 1, similar to the init process on the host. This helps in managing the process lifecycle within containers independently of the host.\n",
    "\n",
    "A **daemon** is a background process that runs continuously and generally performs system-level tasks, like handling network requests, managing system resources, or performing scheduled tasks. They are not typically interactive, meaning they do not have a user interface and do not require user interaction to function. Daemons start at system boot time and run continuously until the system is shut down or they are manually stopped. On Unix-like systems, daemon names typically end with the letter \"d\" (e.g., `httpd` for the Apache HTTP server daemon, `sshd` for the Secure Shell daemon).\n",
    "\n",
    "**dockerd:** The Docker daemon that listens for Docker API requests and manages Docker objects like images, containers, networks, and volumes.\n",
    "\n",
    "A **shim** is a small piece of software that is used to transparently intercept and adapt the interface between different systems or components. It acts as a mediator to ensure compatibility and manage interactions between processes. They are often used to provide compatibility between different versions of software or between different software components.\n",
    "\n",
    "In the context of Docker, shims are used to manage container processes, ensuring that the lifecycle of containers is maintained even if the primary daemon (e.g., Docker daemon) is restarted.\n",
    "\n",
    "**docker-containerd-shim:** This process is created for each container and acts as an intermediary between the container's main process and `containerd`. It allows the container to run independently of the Docker daemon. If the Docker daemon crashes or restarts, the shim ensures that the container process continues to run.\n",
    "\n",
    "1. **Parent PID Namespace:**\n",
    "   - This is the main PID namespace of the host system. It contains the initial processes started by the system, including the init process (`/sbin/init`) with PID 1.\n",
    "\n",
    "2. **Processes in the Parent PID Namespace:**\n",
    "   - **/sbin/init** (PID 1): The first process started by the Linux kernel at boot time.\n",
    "   - **dockerd** (PID 121): The Docker daemon process.\n",
    "   - **docker-containerd** (PID 154): A container runtime process that manages the lifecycle of containers.\n",
    "\n",
    "3. **Child PID Namespaces:**\n",
    "   - Each container runs in its own PID namespace, which is a child of the parent PID namespace. This means that processes within a container can have PID 1 within their namespace.\n",
    "\n",
    "4. **docker-containerd-shim:**\n",
    "   - **docker-containerd-shim** (PID 194 and 234): These processes act as shims, which serve as parent processes to the container processes. They help manage the container's lifecycle and keep the container running even if the Docker daemon crashes or restarts.\n",
    "\n",
    "5. **Containers:**\n",
    "   - **Container 1 (Child PID Namespace 1):**\n",
    "     - **Process:** `/usr/bin/java`\n",
    "     - **PID:** 334 in the container's PID namespace, 1 in the parent PID namespace.\n",
    "   - **Container 2 (Child PID Namespace 2):**\n",
    "     - **Process:** `redis-server`\n",
    "     - **PID:** 267 in the container's PID namespace, 1 in the parent PID namespace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/docker_architecture.png\"  style=\"width:26%;\"/>\n",
    "\n",
    "As camadas de orchestration fazem as tarefas de integração entre os containers dentro de uma máquina. O ´docker-composer´ só enxerga os containers que estão dentro de uma máquina. Quando há mais de uma máquina, é necessário utilizar soluções do tipo ´swarm´, para gerenciar clusters em nós físicos diferentes.\n",
    "\n",
    "### Orchestration Layer\n",
    "\n",
    "**Swarm:**\n",
    "Docker Swarm is the native clustering and orchestration tool for Docker. It allows you to manage a cluster of Docker nodes as a single virtual system.\n",
    "- Manages clusters (swarms) of Docker nodes.\n",
    "- Provides services like load balancing, scaling, and desired state reconciliation.\n",
    "- Facilitates the deployment and management of multi-container applications across multiple Docker hosts.\n",
    "\n",
    "### Engine/Daemon Layer\n",
    "\n",
    "This layer represents the core Docker Engine, which includes several sub-components responsible for container management.\n",
    "\n",
    "**Remote API:**\n",
    "- The Docker Engine API allows communication with the Docker daemon using HTTP endpoints.\n",
    "- Enables users and tools to interact with Docker, issuing commands to manage containers, images, networks, and volumes.\n",
    "\n",
    "**Networking:**\n",
    "- Manages the networking aspects of containers, including creating and configuring Docker networks.\n",
    "- Provides connectivity between containers, both within a single host and across multiple hosts in a swarm.\n",
    "\n",
    "**Volumes:**\n",
    "- Manages data persistence and storage volumes for containers.\n",
    "- Allows containers to share data and store persistent data beyond the lifecycle of a container.\n",
    "\n",
    "**Docker volumes** are a mechanism for persisting data generated by and used by Docker containers. Volumes are stored outside the container's filesystem and are managed by Docker. They provide a way to share data between containers and to ensure data persistence beyond the lifecycle of individual containers.\n",
    "\n",
    "**Image Management:**\n",
    "- Manages Docker images, including pulling, pushing, and storing images in registries.\n",
    "- Provides tools for creating, distributing, and managing container images.\n",
    "\n",
    "### Runtime Layer\n",
    "\n",
    "The runtime layer is responsible for the execution of containers. It consists of higher-level and lower-level runtimes.\n",
    "\n",
    "**containerd:**\n",
    "- A higher-level runtime that provides core container runtime services.\n",
    "- Manages the lifecycle of containers, including tasks like starting, stopping, and deleting containers.\n",
    "- Interacts with lower-level runtimes like `runc`.\n",
    "\n",
    "**runc:**\n",
    "- A low-level runtime responsible for running individual containers.\n",
    "- Implements the Open Container Initiative (OCI) runtime specification.\n",
    "- Directly interacts with the Linux kernel to create and manage container processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/docker_architecture_2.png\"  style=\"width:50%;\"/>\n",
    "\n",
    "**Docker engine** conversa com o **Docker client**. \n",
    "\n",
    "#### REST Interface\n",
    "- **REST Interface:**\n",
    "  - The Docker Engine provides a REST API that allows users and applications to interact with Docker programmatically. This API is used for managing Docker objects such as images, containers, networks, and volumes.\n",
    "\n",
    "#### Docker Engine\n",
    " The core component of Docker, responsible for managing containers. It consists of several sub-components, each handling specific aspects of container management. Composed of:\n",
    " \n",
    "1. **libcontainerd:**\n",
    "   - This library is responsible for managing the container lifecycle. It provides the necessary functions to start, stop, and monitor containers.\n",
    "\n",
    "2. **libnetwork:**\n",
    "   - Handles the networking aspects of Docker. It provides the functionality to create and manage Docker networks, allowing containers to communicate with each other and with the outside world.\n",
    "\n",
    "3. **graph:**\n",
    "   - Manages Docker images, including storing and retrieving image layers. It ensures efficient storage and transfer of images.\n",
    "\n",
    "4. **plugins:**\n",
    "   - Docker supports a plugin architecture that allows third-party tools to extend Docker’s functionality. Plugins can provide additional storage, networking, and other capabilities.\n",
    "\n",
    "#### containerd + runc\n",
    "- **containerd:**\n",
    "  - A higher-level container runtime that manages the lifecycle of containers. It interacts with the lower-level runtime (runc) to execute containers.\n",
    "\n",
    "- **runc:**\n",
    "  - A low-level container runtime that directly interacts with the operating system to run containers. It implements the Open Container Initiative (OCI) runtime specification.\n",
    "\n",
    "#### Control Groups\n",
    "- **Control Groups (cgroups):**\n",
    "  - A Linux kernel feature that limits, accounts for, and isolates the resource usage (CPU, memory, disk I/O, network) of a group of processes. Docker uses cgroups to allocate resources to containers.\n",
    "\n",
    "#### Namespaces\n",
    "- **Namespaces:**\n",
    "  - Another Linux kernel feature that provides isolation between processes. Namespaces ensure that containers have their own isolated environment for process IDs, network interfaces, mounts, and more.\n",
    "  - Types of namespaces include:\n",
    "    - **Pid (Process ID) namespace:** Isolates process IDs.\n",
    "    - **Net (Network) namespace:** Isolates network interfaces.\n",
    "    - **Ipc (Inter-process Communication) namespace:** Isolates IPC resources.\n",
    "    - **Mnt (Mount) namespace:** Isolates filesystem mount points.\n",
    "    - **Ufs (User Filesystem) namespace:** Isolates user IDs and group IDs.\n",
    "\n",
    "#### Layer Capabilities\n",
    "- **Layer Capabilities:**\n",
    "  - Docker uses a union filesystem to manage image layers. This allows Docker to efficiently store and manage the layers of Docker images.\n",
    "  - Supported filesystems include:\n",
    "    - **AUFS (Advanced Multi-Layered Unification Filesystem)**\n",
    "    - **OverlayFS**\n",
    "    - **btrfs (B-Tree Filesystem)**\n",
    "    - **vfs (Virtual Filesystem)**\n",
    "    - **zfs (Zettabyte Filesystem)**\n",
    "    - **DeviceMapper**\n",
    "\n",
    "#### Operating System\n",
    "- **Operating System:**\n",
    "  - The foundation of the Docker architecture. Docker relies on various OS-level features (such as cgroups and namespaces) to provide containerization. The operating system manages hardware resources and provides the necessary environment for Docker to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/docker_components.png\"  style=\"width:50%;\"/>\n",
    "\n",
    "O client permite a execução, criação e destruição de containers; chamadas e execução de imagens.\n",
    "\n",
    "#### Docker Engine\n",
    "The Docker Engine is the core part of Docker, consisting of several components that work together to enable containerization.\n",
    "\n",
    "1. **Client (Docker CLI):**\n",
    "   - The Docker Command Line Interface (CLI) is the user interface for Docker. It allows users to interact with Docker through commands like `docker build`, `docker pull`, and `docker run`.\n",
    "\n",
    "2. **REST API:**\n",
    "   - The Docker REST API allows communication between the Docker CLI and the Docker Daemon. It is used for issuing commands to manage Docker objects like containers, images, networks, and volumes programmatically.\n",
    "\n",
    "3. **Server (Docker Daemon):**\n",
    "   - The Docker Daemon (`dockerd`) listens for Docker API requests and manages Docker objects. It is responsible for building, running, and managing Docker containers.\n",
    "\n",
    "#### Docker Host\n",
    "The Docker Host is the machine (physical or virtual) where the Docker Daemon runs. It provides the environment necessary for containers to run.\n",
    "\n",
    "1. **Docker Client:**\n",
    "   - The Docker Client sends commands to the Docker Daemon via the Docker REST API. Commands include building images, pulling images from registries, and running containers.\n",
    "\n",
    "2. **Docker Daemon:**\n",
    "   - The Docker Daemon handles all container-related tasks, such as building, running, and distributing containers. It interacts with the Docker Registry to pull images and manage containers on the host.\n",
    "\n",
    "3. **Container:**\n",
    "   - A container is an instance of a Docker image. It encapsulates the application and its dependencies, providing an isolated environment for the application to run.\n",
    "\n",
    "#### Docker Registry\n",
    "- **Registry:**\n",
    "  - A Docker Registry is a storage and distribution system for Docker images. The registry can be public (like Docker Hub) or private. It allows users to share and distribute container images.\n",
    "\n",
    "#### Functions of Docker Registry:\n",
    "1. **Images:**\n",
    "   - Docker images are stored in the registry. These images can be pulled by the Docker Daemon to create containers. Images are the building blocks of containers, containing the application and its dependencies.\n",
    "\n",
    "#### Workflow Example\n",
    "1. **Build:**\n",
    "   - A user runs `docker build` from the CLI to create an image from a Dockerfile. The CLI sends this command to the Docker Daemon through the REST API.\n",
    "   \n",
    "2. **Pull:**\n",
    "   - The user can run `docker pull` to fetch an image from the Docker Registry. The CLI sends this command to the Docker Daemon, which pulls the image from the registry.\n",
    "\n",
    "3. **Run:**\n",
    "   - The user runs `docker run` to create and start a container from an image. The CLI sends this command to the Docker Daemon, which starts the container on the Docker Host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/diagram.png\"  style=\"width:50%;\"/>\n",
    "\n",
    "**docker pull**: baixa imagem de um repositório (docker registry) para a sua máquina para ser executado.\n",
    "\n",
    "**docker run**: executa uma imagem.\n",
    "\n",
    "**docker push**: envia uma imagem para o repositório.\n",
    "\n",
    "**docker build**: cria uma receita; a partir da imagem-base que se fez pull, dá diretrizes do que é necessário para instalar as novas ferramentas necessárias para configurar o ambiente e gerar a aplicação (então se tem uma receita para se obter a imagem final desejada). Essa receita está no **dockerfile**. O build aplica, a partir do dockerfile, as transformações necessárias das imagens para se chegar numa imagem final.\n",
    "\n",
    "Uma imagem pode ser baixada (ex. Ubuntu, Debian) e partir disso se faz modificações, até se chegar numa imagem diferente (a original modificada). A partir daí pode dar push.\n",
    "\n",
    "O código é um arquivo binário que está no disco, por exemplo; ao se alocar recursos e executar esse código-objeto, ele vira um processo. O processo é a imagem do código-objeto em execução (é o código-objeto + recursos para que ele possa ser executado (processador, memória, disco, ...)). As imagens são executadas na forma de containers. \n",
    "\n",
    "**docker build:**\n",
    "Sends a build command to the Docker Daemon via the REST API to create a Docker image from a Dockerfile.\n",
    "  \n",
    "**docker pull:**\n",
    "Sends a pull command to the Docker Daemon via the REST API to download an image from the Docker Registry/Hub.\n",
    "  \n",
    "**docker run:**\n",
    "Sends a run command to the Docker Daemon via the REST API to create and start a container from an image.\n",
    "  \n",
    "**docker push:**\n",
    "Sends a push command to the Docker Daemon via the REST API to upload an image to the Docker Registry/Hub.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/images_containers.png\"  style=\"width:60%;\"/>\n",
    "\n",
    "1. **Dockerfile:**\n",
    "A text file containing a set of instructions used to build a Docker image. It defines the environment in which a containerized application will run.\n",
    "\n",
    "2. **Images:**\n",
    "Read-only templates used to create Docker containers. An image includes the application code, libraries, dependencies, and other files needed to run an application.\n",
    "\n",
    "3. **Containers:**\n",
    "Runtime instances of Docker images. Containers are isolated environments where applications run. They are created from images and can be started, stopped, restarted, and removed.\n",
    "\n",
    "4. **Local Docker Instance:**\n",
    "The Docker environment running on your local machine, managing images and containers.\n",
    "\n",
    "5. **Docker Registry:**\n",
    "A storage system for Docker images. It can be a public registry like Docker Hub or a private registry. The registry allows you to push (upload) and pull (download) images.\n",
    "\n",
    "6. **Backup (backup.tar):**\n",
    "A mechanism to save the state of Docker images or containers into a tar file, which can later be loaded back into the Docker environment.\n",
    "\n",
    "- **build:** The Dockerfile is used to build an image. The `docker build` command reads the instructions in the Dockerfile and creates an image.\n",
    "- **tag:** Assigns a tag to an image for easier reference. Tagging helps manage multiple versions of images.\n",
    "- **push:** Uploads an image to a Docker registry. This allows sharing the image with others or using it on different systems.\n",
    "- **pull:** Downloads an image from a Docker registry to the local Docker instance.\n",
    "- **save:** Saves an image to a tar file (`backup.tar`). This can be used for backup purposes or to transfer the image without using a registry.\n",
    "- **load:** Loads an image from a tar file back into the local Docker instance.\n",
    "- **run:** Creates and starts a new container from an image.\n",
    "- **stop/start/restart:** Controls the state of running containers. You can stop a running container, start a stopped container, or restart a container.\n",
    "- **commit:** Creates a new image from a container’s changes. If you modify a running container and want to save the changes as a new image, you can commit the container.\n",
    "\n",
    "1. **Building and Tagging an Image:**\n",
    "   - Create a Dockerfile with the necessary instructions.\n",
    "   - Run `docker build -t my_image:latest .` to build an image from the Dockerfile and tag it as `my_image:latest`.\n",
    "\n",
    "2. **Running a Container:**\n",
    "   - Use `docker run -d --name my_container my_image:latest` to create and start a new container named `my_container` from the `my_image:latest` image.\n",
    "\n",
    "3. **Modifying and Committing a Container:**\n",
    "   - Make changes to the running container (e.g., installing new software).\n",
    "   - Run `docker commit my_container my_image:modified` to create a new image (`my_image:modified`) from the modified container.\n",
    "\n",
    "4. **Pushing an Image to a Registry:**\n",
    "   - Run `docker push my_image:modified` to upload the new image to a Docker registry.\n",
    "\n",
    "5. **Saving and Loading an Image:**\n",
    "   - Save the image to a tar file using `docker save -o backup.tar my_image:modified`.\n",
    "   - Load the image back into Docker using `docker load -i backup.tar`.\n",
    "\n",
    "6. **Starting, Stopping, and Restarting Containers:**\n",
    "   - Start a stopped container with `docker start my_container`.\n",
    "   - Stop a running container with `docker stop my_container`.\n",
    "   - Restart a container with `docker restart my_container`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/lifecycle.png\"  style=\"width:50%;\"/>\n",
    "\n",
    "1. **Created:**\n",
    "   - **State:** The container has been created but not started.\n",
    "   - **Transition to Running:** `docker start <container_id>`\n",
    "   - **Transition to Deleted:** `docker rm <container_id>`\n",
    "\n",
    "2. **Running:**\n",
    "   - **State:** The container is actively running.\n",
    "   - **Transition to Paused:** `docker pause <container_id>`\n",
    "   - **Transition from Paused to Running:** `docker unpause <container_id>`\n",
    "   - **Transition to Stopped:** `docker stop <container_id>`\n",
    "\n",
    "3. **Paused:**\n",
    "   - **State:** The container's processes are paused.\n",
    "   - **Transition to Running:** `docker unpause <container_id>`\n",
    "\n",
    "4. **Stopped:**\n",
    "   - **State:** The container has been stopped but still exists.\n",
    "   - **Transition to Running:** `docker start <container_id>`\n",
    "   - **Transition to Deleted:** `docker rm <container_id>`\n",
    "\n",
    "5. **Deleted:**\n",
    "   - **State:** The container has been removed and no longer exists.\n",
    "\n",
    "- **Creating a Container:**\n",
    "  ```sh\n",
    "  docker create <image_name>\n",
    "  ```\n",
    "  This command creates a container from a specified image but does not start it.\n",
    "\n",
    "- **Running a Container:**\n",
    "  ```sh\n",
    "  docker run <image_name>\n",
    "  ```\n",
    "  This command creates and starts a container from an image in one step.\n",
    "\n",
    "- **Starting a Container:**\n",
    "  ```sh\n",
    "  docker start <container_id>\n",
    "  ```\n",
    "  This command starts a container that has been created or stopped.\n",
    "\n",
    "- **Stopping a Container:**\n",
    "  ```sh\n",
    "  docker stop <container_id>\n",
    "  ```\n",
    "  This command stops a running container.\n",
    "\n",
    "- **Pausing a Container:**\n",
    "  ```sh\n",
    "  docker pause <container_id>\n",
    "  ```\n",
    "  This command pauses all processes in a running container.\n",
    "\n",
    "- **Unpausing a Container:**\n",
    "  ```sh\n",
    "  docker unpause <container_id>\n",
    "  ```\n",
    "  This command unpauses all processes in a paused container.\n",
    "\n",
    "- **Removing a Container:**\n",
    "  ```sh\n",
    "  docker rm <container_id>\n",
    "  ```\n",
    "  This command removes a stopped or created container from the system.\n",
    "\n",
    "1. **Create a Container:**\n",
    "   ```sh\n",
    "   docker create --name my_container my_image\n",
    "   ```\n",
    "\n",
    "2. **Start the Container:**\n",
    "   ```sh\n",
    "   docker start my_container\n",
    "   ```\n",
    "\n",
    "3. **Pause the Container:**\n",
    "   ```sh\n",
    "   docker pause my_container\n",
    "   ```\n",
    "\n",
    "4. **Unpause the Container:**\n",
    "   ```sh\n",
    "   docker unpause my_container\n",
    "   ```\n",
    "\n",
    "5. **Stop the Container:**\n",
    "   ```sh\n",
    "   docker stop my_container\n",
    "   ```\n",
    "\n",
    "6. **Remove the Container:**\n",
    "   ```sh\n",
    "   docker rm my_container\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Docker image is a file used to execute code in a Dockier container. Docker images act as a set of instructions to build a Docker container, such as a template. Docker images also act as the strating point when using Docker.\n",
    "\n",
    "A Docker image contains application code, libraries, tools, dependecies and other files needed to make an application run. When a user runs an image, it can become one or many instances of a container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dockerfile\n",
    "\n",
    "A Dockerfile is a text file that contains instructions for the Docker daemon to use when building a container image. It provides information on the commands to run, files to copy, startup command, and more.\n",
    "\n",
    "- Dockerfiles can be used to create automated builds that execute several command-line instructions in succession. They can also enable greater flexibility and portability of business applications. For example, IT organizations can use Dockerfiles to package applications and their dependencies in a virtual container that can run on premises, in public or private clouds, or on bare metal.\n",
    "\n",
    "- Docker supports over 15 different instructions in Dockerfiles, including:\n",
    "\n",
    "  - **FROM:** Refers to an existing image as the base for your build\n",
    "  - **COPY:** Adds files and folders to your image's filesystem\n",
    "  - **ENV:** Sets environment variables that will be available within your containers\n",
    "  - **RUN:** Executes commands within the container at build time\n",
    "  - **USER:** Changes the current directory\n",
    "  - **ADD:** Copies files and directories to the image and creates a new layer\n",
    "  - **CMD:** Sets default arguments for container start\n",
    "  - **ENTRYPOINT:** Sets default command for container start\n",
    "  - **EXPOSE:** Defines port assignments for running container\n",
    "  - **VOLUME:** Includes directory in the image as a volume when starting the container in the host system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/aula03/teste1.png\"  style=\"width:50%;\"/>\n",
    "\n",
    "In virtual environments, each application runs on its own kernel. This is because virtual machines (VMs) provide complete isolation and include a full operating system instance with its own kernel. Containers, on the other hand, share the host system's kernel and do not run separate kernels for each application.\n",
    "\n",
    "\n",
    "<img src=\"figs/aula03/teste2.png\" style=\"width:50%;\"/>\n",
    "\n",
    "In containerization, images are used to create and deploy containers. These images contain everything needed to run a piece of software, including the code, runtime, libraries, and dependencies. Virtualization can also use images (often called VM images) to create virtual machines, but the term \"images\" is more commonly associated with containerization.\n",
    "\n",
    "\n",
    "<img src=\"figs/aula03/teste3.png\" style=\"width:50%;\"/>\n",
    "\n",
    "Containers share the host system's kernel but have their own isolated user space. This allows containers to run multiple isolated applications on the same host operating system while sharing the same kernel.\n",
    "\n",
    "\n",
    "<img src=\"figs/aula03/teste4.png\" style=\"width:50%;\"/>\n",
    "\n",
    "Virtualization uses a hypervisor to create and manage virtual machines. The hypervisor allows multiple operating systems to share a single hardware host by abstracting and partitioning the underlying hardware. Containerization, on the other hand, does not use a hypervisor; it relies on the host operating system's kernel to provide isolation and resource management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Your Own Docker with Linux Namespaces, cgroups, and chroot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://akashrajpurohit.com/blog/build-your-own-docker-with-linux-namespaces-cgroups-and-chroot-handson-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `sudo su` is used to switch the current user to the superuser (root) in a Linux/Unix system. **`su`**: This stands for \"substitute user\" or \"switch user.\" When used without any arguments, `su` switches to the superuser (root) by default. You can also specify another user by using `su [username]`.\n",
    "\n",
    "To create an isolated environment, we start by setting up a new namespace. We use the `unshare` command, specifying different namespaces `(--uts, --pid, --net, --mount, and --ipc)`, which provide separate instances of system identifiers and resources for our container.\n",
    "\n",
    "```\n",
    "unshare --uts --pid --net --mount --ipc --fork\n",
    "```\n",
    "\n",
    "`--uts`, `--pid`, `--net`, `--mount`, and `--ipc` are parameters of the `unshare` command that specify the types of namespaces to be created for the new isolated environment. Here’s what each of these parameters means:\n",
    "\n",
    "- `--uts`: UTS namespace, which allows isolation of hostname and domain name.\n",
    "- `--pid`: PID namespace, which isolates the process ID number space.\n",
    "- `--net`: Network namespace, which isolates network interfaces.\n",
    "- `--mount`: Mount namespace, which isolates the set of filesystem mount points.\n",
    "- `--ipc`: IPC namespace, which isolates inter-process communication resources.\n",
    "\n",
    "These parameters define different types of namespaces, creating separate instances of system identifiers and resources within the new namespace. When you run the command `unshare --uts --pid --net --mount --ipc --fork`, you are specifying that the new isolated environment should include all these types of namespaces.\n",
    "\n",
    "Ao dar `unshare --uts`, eu consigo mudar o nome da minha máquina (só vale para mim)\n",
    "\n",
    "The `--fork` option in the `unshare` command is used to fork a new process within the newly created namespaces. Essentially, it means that the `unshare` command will not only create the specified namespaces but also start a new process within those namespaces.\n",
    "\n",
    "Here's a breakdown of what happens with `--fork`:\n",
    "\n",
    "- Without `--fork`: The `unshare` command would modify the namespaces of the current process. This means the current shell or script that ran the `unshare` command would be in the new namespaces.\n",
    "- With `--fork`: The `unshare` command creates the new namespaces and then forks (creates a new process). The new process will be running in the new namespaces, while the parent process remains unchanged.\n",
    "\n",
    "Using `--fork` is helpful because it keeps the parent process unchanged and spawns a new process within the isolated environment, allowing you to work within the new namespaces without affecting the current shell or script.\n",
    "\n",
    "So, the complete command `unshare --uts --pid --net --mount --ipc --fork` does the following:\n",
    "1. Creates new UTS, PID, network, mount, and IPC namespaces.\n",
    "2. Forks a new process that runs within these newly created namespaces.\n",
    "\n",
    "The `unshare` command in Linux is used to run a program with some namespaces unshared from the parent process. It allows you to create separate namespaces for various system resources like UTS (hostname), PID (process ID), network, mount points, IPC (inter-process communication), etc. When you use multiple flags with `unshare`, it isolates those namespaces.\n",
    "\n",
    "The `--fork` option tells `unshare` to create a new process after unsharing the specified namespaces. When `--fork` is used, `unshare` will execute the specified command or shell in a child process, leaving the parent process unchanged. This new child process will be running in the new namespaces that were specified.\n",
    "\n",
    "### Example:\n",
    "When you run:\n",
    "```sh\n",
    "unshare --uts --pid --net --mount --ipc --fork\n",
    "```\n",
    "This does the following:\n",
    "- **`--uts`**: Unshares the UTS namespace (hostname and domain name).\n",
    "- **`--pid`**: Unshares the PID namespace (process IDs).\n",
    "- **`--net`**: Unshares the network namespace.\n",
    "- **`--mount`**: Unshares the mount namespace (file system mount points).\n",
    "- **`--ipc`**: Unshares the IPC namespace.\n",
    "- **`--fork`**: Forks a new process to run the specified command in the newly created namespaces.\n",
    "\n",
    "A partir disso, as mudanças que eu faço (por exemplo, mudar o nome da máquina), não são vistas de fora\n",
    "\n",
    "### Without `--fork`:\n",
    "If you don't use `--fork`, the `unshare` command would unshare the namespaces in the current shell process. This means the current shell itself would be running in the new namespaces, and when it exits, all changes would be lost as there would be no process remaining in the new namespaces.\n",
    "\n",
    "### With `--fork`:\n",
    "By using `--fork`, the `unshare` command starts a new process in the new namespaces, leaving the current shell intact. This new process can then run a command or shell and continue operating in the new namespaces even after the `unshare` command completes.\n",
    "\n",
    "### Practical Use:\n",
    "```sh\n",
    "unshare --uts --pid --net --mount --ipc --fork /bin/bash\n",
    "```\n",
    "This command would start a new bash shell in a new set of namespaces for UTS, PID, network, mount, and IPC. The new bash shell will be running in an isolated environment, and you can perform operations in this shell without affecting the parent environment.\n",
    "\n",
    "Tive que dar sudo pra funcionar:\n",
    "\n",
    "```\n",
    "sudo unshare --uts --pid --net --mount --ipc --fork\n",
    "```\n",
    "\n",
    "Dando sudo, ele vai pro root (ou seja, ao invés de alexfidalgo@alexfidalgo, vira root@alexfidalgo).\n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~$ sudo unshare --uts --pid --net --mount --ipc --fork\n",
    "root@alexfidalgo:/home/alexfidalgo# hostname\n",
    "alexfidalgo\n",
    "root@alexfidalgo:/home/alexfidalgo# hostname alexfidalgounshared\n",
    "root@alexfidalgo:/home/alexfidalgo# hostname\n",
    "alexfidalgounshared\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criada uma imagem do que já havia antes e, a partir de agora, qualquer modificação não será visível.\n",
    "\n",
    "Se eu abro um novo terminal no alexfidalgo (ou seja, na VM):\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~$ hostname\n",
    "alexfidalgo\n",
    "```\n",
    "\n",
    "Ou seja, isso do hostname alexfidalgounshared tá restrito ao processo lá no primeiro terminal.\n",
    "\n",
    "No terminal do alexfidalgounshared, temos:\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo# ps\n",
    "    PID TTY          TIME CMD\n",
    "   2303 pts/2    00:00:00 sudo\n",
    "   2304 pts/2    00:00:00 unshare\n",
    "   2305 pts/2    00:00:00 bash\n",
    "   3043 pts/2    00:00:00 ps\n",
    "```\n",
    "- `2303`: The `sudo` command that you ran to elevate privileges.\n",
    "- `2304`: The `unshare` command itself.\n",
    "- `2305`: The new `bash` shell created by `unshare`.\n",
    "- `3043`: The `ps` command you just ran.\n",
    "\n",
    "No terminal do alexfidalgo, temos:\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~$ ps\n",
    "    PID TTY          TIME CMD\n",
    "   3026 pts/3    00:00:00 bash\n",
    "   3042 pts/3    00:00:00 ps\n",
    "```\n",
    "- `3026`: The `bash` shell running in this new terminal.\n",
    "- `3042`: The `ps` command you just ran.\n",
    "\n",
    "- In the terminal where you ran `unshare`, the processes listed by `ps` (2303, 2304, 2305, 3043) are all running within the new PID namespace created by `unshare`.\n",
    "- In the new terminal, the processes listed (3026, 3042) are running in the host's PID namespace. They do not see the processes from the isolated namespace created by `unshare`.\n",
    "- The new terminal you opened is not part of the unshared namespaces. It runs in the original host namespaces.\n",
    "- The terminal where you executed `unshare` and got the new `bash` shell is operating in the isolated namespaces created by the `unshare` command.\n",
    "\n",
    "The `ps` command is used to display information about active processes. It stands for \"process status.\" The command can show a snapshot of the current processes, including their IDs, status, CPU usage, memory usage, and more.\n",
    "\n",
    "A PID, or Process ID, is a unique identifier assigned by the operating system to each process running on a system. The PID is used to manage and reference processes. Each process has its own PID, and no two processes on the same system will have the same PID at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **`echo \"Current PID: $$\"`**\n",
    "   - **`$$`**: This special variable in the shell holds the PID of the currently running shell or script.\n",
    "   - **`echo \"Current PID: $$\"`**: This command prints the PID of the current shell. The `echo` command outputs the string \"Current PID: \" followed by the value of `$$`, which is the PID of the shell executing the command.\n",
    "\n",
    "2. **`echo \"Parent PID: $(ps -o ppid= -p $$)\"`**\n",
    "   - **`ps`**: This command is used to display information about active processes. \n",
    "   - **`-o ppid=`**: This option specifies that `ps` should output the parent PID (PPID) of the process.\n",
    "   - **`-p $$`**: This option tells `ps` to display information for the process with the PID given by `$$` (i.e., the current shell).\n",
    "   - **`$(...)`**: This syntax is used to execute a command and substitute its output in place. Here, `$(ps -o ppid= -p $$)` executes `ps -o ppid= -p $$` and replaces the `$(...)` with the output of that command.\n",
    "   - **`echo \"Parent PID: $(ps -o ppid= -p $$)\"`**: This command prints the PPID (parent PID) of the current shell. The `ps` command is run to get the PPID, and `echo` outputs the string \"Parent PID: \" followed by the value returned by the `ps` command.\n",
    "\n",
    "In the unshared terminal:\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo#      echo \"Current PID: $$\"\n",
    "     echo \"Parent PID: $(ps -o ppid= -p $$)\"\n",
    "Current PID: 1\n",
    "Parent PID:       0\n",
    "```\n",
    "\n",
    "In the new terminal:\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~$      echo \"Current PID: $$\"\n",
    "     echo \"Parent PID: $(ps -o ppid= -p $$)\"\n",
    "Current PID: 3026\n",
    "Parent PID:    3025\n",
    "```\n",
    "\n",
    "The PIDs  start from a low number (1, 2, 3, ...) in the unshared terminal, indicating it's a new PID namespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the cgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cgroups (control groups) help manage resource allocation and control the usage of system resources by our containerized processes.\n",
    "\n",
    "We will create a new cgroup for our container and assign CPU quota limits to restrict its resource usage.\n",
    "```\n",
    "mkdir /sys/fs/cgroup/cpu/container1\n",
    "echo 100000 > /sys/fs/cgroup/cpu/container1/cpu.cfs_quota_us\n",
    "echo 0 > /sys/fs/cgroup/cpu/container1/tasks\n",
    "echo $$ > /sys/fs/cgroup/cpu/container1/tasks\n",
    "```\n",
    "O primeiro comando gerou o erro *mkdir: ccannot create directory, no such file or directory*.\n",
    "\n",
    "The error message `No such file or directory` indicates that the path `/sys/fs/cgroup/cpu` does not exist. This can happen if the CPU cgroup subsystem is not mounted or the directory structure is different on your system. To resolve this, you need to ensure that the cgroup filesystem is properly mounted and the necessary directories are created.\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/# mount | grep cgroup\n",
    "cgroup2 on /sys/fs/cgroup type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate,memory_recursiveprot)\n",
    "\n",
    "```\n",
    "It looks like your system is using cgroup version 2 (`cgroup2`). With cgroup v2, the hierarchy and the way you create and manage cgroups are a bit different compared to cgroup v1. In cgroup v2, you don't have separate subsystems like `cpu`, `memory`, etc. Instead, all controllers are unified under a single hierarchy.\n",
    "\n",
    "Navigating to the cgroup2 mount point\n",
    "```sh\n",
    "cd /sys/fs/cgroup\n",
    "```\n",
    "\n",
    "Create a new directory for your cgroup\n",
    "```sh\n",
    "mkdir container1\n",
    "```\n",
    "\n",
    "Navigate to the newly created directory\n",
    "```sh\n",
    "cd container1\n",
    "```\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# ls\n",
    "cgroup.controllers      cgroup.subtree_control  cpu.uclamp.max         cpuset.mems.effective  memory.events.local  memory.stat\n",
    "cgroup.events           cgroup.threads          cpu.uclamp.min         io.max                 memory.high          memory.swap.current\n",
    "cgroup.freeze           cgroup.type             cpu.weight             io.pressure            memory.low           memory.swap.events\n",
    "cgroup.kill             cpu.idle                cpu.weight.nice        io.prio.class          memory.max           memory.swap.high\n",
    "cgroup.max.depth        cpu.max                 cpuset.cpus            io.stat                memory.min           memory.swap.max\n",
    "cgroup.max.descendants  cpu.max.burst           cpuset.cpus.effective  io.weight              memory.numa_stat     pids.current\n",
    "cgroup.procs            cpu.pressure            cpuset.cpus.partition  memory.current         memory.oom.group     pids.events\n",
    "cgroup.stat             cpu.stat                cpuset.mems            memory.events          memory.pressure      pids.max\n",
    "\n",
    "```\n",
    "\n",
    "Now, you can see various files and directories related to cgroup control.\n",
    "\n",
    "Let's list the available controllers:\n",
    "```sh\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# cat cgroup.controllers\n",
    "cpuset cpu io memory pids\n",
    "```\n",
    "\n",
    "The files you see inside the newly created `container1` directory are automatically created by the cgroup v2 system. This behavior is by design and is part of how cgroups manage resources.\n",
    "\n",
    "When you create a directory within the cgroup filesystem (`/sys/fs/cgroup`), the kernel automatically populates it with the necessary control files. These files and directories are used to configure and monitor the cgroup. This allows you to manage various aspects of the processes that will belong to this cgroup, such as CPU usage, memory limits, I/O priorities, etc.\n",
    "\n",
    "Here are some key files and their purposes:\n",
    "\n",
    "- **`cgroup.controllers`**: Lists the controllers that are available for the cgroup hierarchy.\n",
    "- **`cgroup.subtree_control`**: Enables or disables controllers for the cgroup and its children.\n",
    "- **`cgroup.procs`**: Lists the processes belonging to this cgroup.\n",
    "- **`cpu.max`**: Configures the maximum CPU usage for the cgroup.\n",
    "- **`memory.max`**: Sets the maximum memory limit for the cgroup.\n",
    "- **`pids.max`**: Limits the number of processes in the cgroup.\n",
    "\n",
    "The command `echo 100000 > cpu.cfs_quota_us` configures the CPU usage limit for processes in a cgroup using the cgroup v1 CPU controller.\n",
    "- **`cpu.cfs_quota_us`**: This file is part of the cgroup v1 CPU controller, and it is used to set the total available CPU time for a cgroup during each scheduling period.\n",
    "- **Value (`100000`)**: The value written to `cpu.cfs_quota_us` is specified in microseconds. \n",
    "\n",
    "To understand the full effect of this command, it is important to consider the `cpu.cfs_period_us` file, which specifies the length of each scheduling period in microseconds. By default, `cpu.cfs_period_us` is usually set to `100000` microseconds (100 milliseconds).\n",
    "\n",
    "In cgroup v2, the CPU resource control is handled differently compared to cgroup v1. Instead of using `cpu.cfs_quota_us` and `cpu.cfs_period_us`, you use the `cpu.max` file to set CPU limits.\n",
    "\n",
    "The `cpu.max` file in cgroup v2 is used to set the maximum CPU time that processes in the cgroup can use. It takes two values:\n",
    "- The maximum amount of CPU time a group can use in microseconds.\n",
    "- The period in microseconds over which this quota is enforced.\n",
    "\n",
    "For example, to set a limit similar to `cpu.cfs_quota_us` in cgroup v1 (where you set a quota of 100000 microseconds in a period of 100000 microseconds, effectively 100% of one CPU core):\n",
    "\n",
    "```sh\n",
    "echo \"100000 100000\" > cpu.max\n",
    "```\n",
    "This command sets the CPU quota to 100000 microseconds (100 milliseconds) in a 100000 microsecond period, allowing the cgroup to use 100% of one CPU core.\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# cat cpu.max\n",
    "max 100000\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# echo \"100000 100000\" > cpu.max\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# cat cpu.max\n",
    "100000 100000\n",
    "\n",
    "```\n",
    "\n",
    "O equivalente dos comandos\n",
    "```\n",
    "echo 0 > /sys/fs/cgroup/cpu/container1/tasks\n",
    "echo $$ > /sys/fs/cgroup/cpu/container1/tasks\n",
    "```\n",
    "no v2 seria:\n",
    "In cgroup v2, the equivalent of adding the current shell to the cgroup would be to write the current shell's PID to the `cgroup.procs` file.\n",
    "To move the current shell into the cgroup:\n",
    "Navigating to the cgroup v2 directory.\n",
    "```sh\n",
    "cd /sys/fs/cgroup/container1\n",
    "```\n",
    "Getting the PID of the current shell.\n",
    "```sh\n",
    "echo $$\n",
    "```\n",
    "This command outputs the PID of the current shell.\n",
    "Adding the current shell to the cgroup.\n",
    "```sh\n",
    "echo $$ > cgroup.procs\n",
    "```\n",
    "Fiz:\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# echo $$\n",
    "1\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# cat cgroup.procs\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# echo $$ > cgroup.procs\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# cat cgroup.procs\n",
    "1\n",
    "46\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures that any subsequent child processes spawned by the shell or script will also be part of the container1 cgroup, and their resource usage will be subject to the specified CPU quota limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `exit` command exits the unshared namespace.\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/# hostname\n",
    "alexfidalgounshared\n",
    "root@alexfidalgo:/# exit\n",
    "logout\n",
    "alexfidalgo@alexfidalgo:~$ hostname\n",
    "alexfidalgo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Root File System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the file system for our container, we use `debootstrap` to set up a minimal Ubuntu environment within a directory named `\"ubuntu-rootfs\"`.\n",
    "\n",
    "This serves as the root file system for our container.\n",
    "\n",
    "```sh\n",
    "exit\n",
    "sudo apt install debootstrap\n",
    "```\n",
    "\n",
    "To re-enter the unshared namespace, you'll need to use the `unshare` command again to create a new shell within the desired namespaces. \n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~$ hostname\n",
    "alexfidalgo\n",
    "alexfidalgo@alexfidalgo:~$ sudo unshare --uts --pid --net --mount --ipc --fork\n",
    "root@alexfidalgo:/home/alexfidalgo# hostname afunshared\n",
    "root@alexfidalgo:/home/alexfidalgo# hostname\n",
    "afunshared\n",
    "root@alexfidalgo:/home/alexfidalgo# cd /sys/fs/cgroup/container1\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# cat cpu.max\n",
    "100000 100000\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# cat cgroup.procs\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# echo $$ > cgroup.procs\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# cat cgroup.procs\n",
    "1\n",
    "15\n",
    "```\n",
    "Navigate to a directory where you want to create the new root filesystem; for example, you can use your home directory or any other suitable location:\n",
    "   ```sh\n",
    "   cd /home/alexfidalgo\n",
    "   ```\n",
    "\n",
    "Create a directory for the new root filesystem:\n",
    "   ```sh\n",
    "   mkdir -p ubuntu-rootfs\n",
    "   ```\n",
    "Run the `debootstrap` command to create the new root filesystem in the `ubuntu-rootfs` directory:\n",
    "   ```sh\n",
    "   debootstrap focal ./ubuntu-rootfs http://archive.ubuntu.com/ubuntu/\n",
    "   ```\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo# debootstrap focal ./ubuntu-rootfs http://archive.ubuntu.com/ubuntu/\n",
    "I: Retrieving InRelease \n",
    "I: Retrieving Release \n",
    "E: Failed getting release file http://archive.ubuntu.com/ubuntu/dists/focal/Release\n",
    "```\n",
    "Since you previously encountered DNS resolution issues within the unshared network namespace, it's likely that the network configuration in the unshared namespace is causing the problem.\n",
    "\n",
    "I can ping it from my normal terminal, but when I do that from the unshared one, I get an error:\n",
    "\n",
    "```sh\n",
    "alex@alex-inspiron:~$ ping -c 4 archive.ubuntu.com\n",
    "PING archive.ubuntu.com (185.125.190.82) 56(84) bytes of data.\n",
    "64 bytes from archive.ubuntu.com (185.125.190.82): icmp_seq=1 ttl=52 time=203 ms\n",
    "64 bytes from archive.ubuntu.com (185.125.190.82): icmp_seq=2 ttl=52 time=205 ms\n",
    "64 bytes from archive.ubuntu.com (185.125.190.82): icmp_seq=3 ttl=52 time=208 ms\n",
    "64 bytes from archive.ubuntu.com (185.125.190.82): icmp_seq=4 ttl=52 time=243 ms\n",
    "--- archive.ubuntu.com ping statistics ---\n",
    "4 packets transmitted, 4 received, 0% packet loss, time 3002ms\n",
    "rtt min/avg/max/mdev = 202.819/214.740/243.403/16.654 ms\n",
    "\n",
    "root@alexfidalgo:/home/alexfidalgo# ping -c 4 archive.ubuntu.com\n",
    "ping: archive.ubuntu.com: Temporary failure in name resolution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou recriar as configurações. Recriando deu o mesmo erro. E é mais genérico:\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo# ping -c 4 google.com\n",
    "ping: google.com: Temporary failure in name resolution\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que o problema está relacionado à resolução de DNS no ambiente. \n",
    "\n",
    "O arquivo `/etc/resolv.conf` deve conter os servidores DNS que o seu sistema usa para resolver nomes de domínio. Você pode adicionar manualmente um servidor DNS, como o do Google.\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo# sudo echo \"nameserver 8.8.8.8\" > /etc/resolv.conf\n",
    "sudo: unable to resolve host alexfidalgounshared: Temporary failure in name resolution\n",
    "```\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo# echo \"127.0.1.1 alexfidalgounshared\" >> /etc/hosts\n",
    "root@alexfidalgo:/home/alexfidalgo# sudo echo \"nameserver 8.8.8.8\" > /etc/resolv.conf\n",
    "root@alexfidalgo:/home/alexfidalgo# sudo systemctl restart networking\n",
    "Failed to connect to bus: No data available\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error \"Failed to connect to bus: No data available\" indicates that the system is unable to communicate with the `systemd` process manager, likely because your current environment doesn't support it directly (e.g., if you are within a chroot or a minimal container environment).\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo# ip link show\n",
    "1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n",
    "    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n",
    "```\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo# sudo ip link add name eth0 type dummy\n",
    "root@alexfidalgo:/home/alexfidalgo# sudo ip addr add 192.168.1.2/24 dev eth0\n",
    "root@alexfidalgo:/home/alexfidalgo# sudo ip link set eth0 up\n",
    "root@alexfidalgo:/home/alexfidalgo# ip link show\n",
    "1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n",
    "    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n",
    "2: eth0: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n",
    "    link/ether e6:88:06:f3:0a:5b brd ff:ff:ff:ff:ff:ff\n",
    "```\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/home/alexfidalgo# echo \"nameserver 8.8.8.8\" | sudo tee /etc/resolv.conf\n",
    "nameserver 8.8.8.8\n",
    "```\n",
    "\n",
    "Recriei a VM. Antes de alterar namespace e cgroup, o ping do google funcionou.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acho que de dentro do root, eu não consigo rodar esse ping\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# ping -c 4 google.com\n",
    "ping: google.com: Temporary failure in name resolution\n",
    "root@alexfidalgo:/sys/fs/cgroup/container1# exit\n",
    "logout\n",
    "\n",
    "alexfidalgo@alexfidalgo:~$ ping -c 4 google.com\n",
    "PING google.com (142.250.219.142) 56(84) bytes of data.\n",
    "64 bytes from google.com (142.250.219.142): icmp_seq=1 ttl=118 time=6.99 ms\n",
    "64 bytes from google.com (142.250.219.142): icmp_seq=2 ttl=118 time=8.25 ms\n",
    "64 bytes from google.com (142.250.219.142): icmp_seq=3 ttl=118 time=17.8 ms\n",
    "64 bytes from google.com (142.250.219.142): icmp_seq=4 ttl=118 time=7.98 ms\n",
    "--- google.com ping statistics ---\n",
    "4 packets transmitted, 4 received, 0% packet loss, time 3005ms\n",
    "rtt min/avg/max/mdev = 6.994/10.243/17.750/4.359 ms\n",
    "\n",
    "```\n",
    "\n",
    "Vou tentar fazer por fora dos namespaces (me parece que é assim que o professor faz no video).\n",
    "\n",
    "```sh\n",
    "sudo debootstrap focal ./ubuntu-rootfs http://archive.ubuntu.com/ubuntu/\n",
    "```\n",
    "\n",
    "Note que o container1 continua lá:\n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~$ cd /sys/fs/cgroup/container1\n",
    "alexfidalgo@alexfidalgo:/sys/fs/cgroup/container1$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command set up a minimal Ubuntu environment within a directory named `ubuntu-rootfs`.\n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~$ ls ubuntu-rootfs/\n",
    "bin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n",
    "alexfidalgo@alexfidalgo:~$ ls /\n",
    "bin   cdrom  etc   lib    lib64   lost+found  mnt  proc  run   snap  swap.img  tmp  var\n",
    "boot  dev    home  lib32  libx32  media       opt  root  sbin  srv   sys       usr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument `focal` specifies the Ubuntu release to install. In this case, we are installing Ubuntu 20.04 (Focal Fossa).\n",
    "\n",
    "The second argument `./ubuntu-rootfs` specifies the directory to install the Ubuntu environment into. In this case, we are installing it into the `ubuntu-rootfs` directory.\n",
    "\n",
    "The third argument `http://archive.ubuntu.com/ubuntu/` specifies the URL of the Ubuntu repository to use for the installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting and Chrooting into the Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mount essential file systems, such as `/proc`, `/sys`, and `/dev`, within our container’s root file system.\n",
    "\n",
    "A file system is a method and data structure that an operating system uses to manage files on a disk or partition. It organizes files and directories in a way that makes it easy to store, retrieve, and manage data.\n",
    "\n",
    "Mounting is the process of making a file system accessible at a certain point in the directory tree. When you mount a file system, you attach it to an existing directory (the mount point), making the files and directories in that file system accessible.\n",
    "\n",
    "When you are setting up a container, you often need to mount essential file systems into the container's root file system so that processes running inside the container can interact with the system resources and devices as needed.\n",
    "\n",
    "```\n",
    "sudo mount -t proc none ./ubuntu-rootfs/proc\n",
    "```\n",
    "\n",
    "The first command mounts the `proc` filesystem into the `./ubuntu-rootfs/proc` directory. The `proc` filesystem provides information about processes and system resources in a virtual file format.\n",
    "\n",
    "Mounting the `proc` filesystem in the specified directory allows processes within the `./ubuntu-rootfs/` environment to access and interact with the system’s process-related information.\n",
    "\n",
    "The `proc` file system provides information about processes and other system information in a virtual file format. It is essential for many system utilities to function correctly.\n",
    "\n",
    "- **`sudo`**: Runs the command with superuser (root) privileges.\n",
    "- **`mount`**: The command to mount file systems.\n",
    "- **`-t proc`**: Specifies the type of file system to mount. In this case, `proc`.\n",
    "- **`none`**: Since `proc` is a virtual file system, it doesn't have a source device, so `none` is used.\n",
    "- **`./ubuntu-rootfs/proc`**: The directory within the container's root file system where the `proc` file system will be mounted.\n",
    "\n",
    "- **File System**: The file system being mounted is `proc`. This is a special file system in Unix-like operating systems that presents process and system information in a hierarchical file-like structure. It is a virtual file system, meaning it doesn't reside on disk but is dynamically generated by the kernel.\n",
    "\n",
    "- **Mount Point**: The mount point is `./ubuntu-rootfs/proc`. This means you are mounting the `proc` file system to the `proc` directory inside your container's root file system (`ubuntu-rootfs`). The `proc` directory inside `./ubuntu-rootfs` must exist for the mount to succeed.\n",
    "\n",
    "This command mounts the `proc` file system into the `./proc` directory within your container's root file system. Processes running inside the container will be able to access process-related information through this directory.\n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:/home$ cd /home/alexfidalgo/ubuntu-rootfs\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ sudo mkdir -p ./proc\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ sudo mount -t proc none ./proc\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ ls ./proc\n",
    "1    11   1412   15806  197  22   31   439  727  83   97          crypto         ioports      mdstat        self           version\n",
    "10   110  15     16     2    226  32   5    732  84   98          devices        irq          meminfo       slabinfo       version_signature\n",
    "100  112  1504   1609   20   24   33   523  734  85   99          diskstats      kallsyms     misc          softirqs       vmallocinfo\n",
    "101  113  1505   1610   200  241  330  524  735  86   acpi        dma            kcore        modules       stat           vmstat\n",
    "102  114  1513   1643   201  25   331  585  737  861  asound      driver         key-users    mounts        swaps          zoneinfo\n",
    "103  12   1542   1721   204  26   399  6    749  87   bootconfig  dynamic_debug  keys         mtrr          sys\n",
    "104  124  1553   175    206  27   4    638  789  88   buddyinfo   execdomains    kmsg         net           sysrq-trigger\n",
    "105  127  156    176    209  279  432  701  8    90   bus         fb             kpagecgroup  pagetypeinfo  sysvipc\n",
    "106  128  15729  18     21   28   433  717  80   92   cgroups     filesystems    kpagecount   partitions    thread-self\n",
    "107  13   15776  186    212  29   436  718  803  93   cmdline     fs             kpageflags   pressure      timer_list\n",
    "108  133  15779  19     215  3    437  724  81   95   consoles    interrupts     loadavg      schedstat     tty\n",
    "109  14   15784  190    219  30   438  726  82   96   cpuinfo     iomem          locks        scsi          uptime\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ ls\n",
    "bin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "mount -t sysfs none ./ubuntu-rootfs/sys\n",
    "```\n",
    "\n",
    "This command mounts the `sysfs` filesystem into the `./ubuntu-rootfs/sys directory`. The `sysfs` filesystem provides information about devices, drivers, and other kernel-related information in a hierarchical format.\n",
    "\n",
    "Mounting the `sysfs` filesystem in the specified directory enables processes within the `./ubuntu-rootfs/` environment to access and interact with system-related information exposed through the `sysfs` interface.\n",
    "\n",
    "Inicialmente, não tem nada no sys:\n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ cd sys\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs/sys$ ls\n",
    "```\n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ sudo mount -t sysfs none ./sys\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ ls /sys\n",
    "block  bus  class  dev  devices  firmware  fs  hypervisor  kernel  module  power\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ cd /home\n",
    "alexfidalgo@alexfidalgo:/home$ ls /sys\n",
    "block  bus  class  dev  devices  firmware  fs  hypervisor  kernel  module  power\n",
    "```\n",
    "\n",
    "```\n",
    "mount -o bind /dev ./ubuntu-rootfs/dev\n",
    "```\n",
    "\n",
    "Finally we bind the `/dev` directory to the `./ubuntu-rootfs/dev` directory. The `/dev` directory contains device files that represent physical and virtual devices on the system.\n",
    "\n",
    "By binding the `/dev` directory to the `./ubuntu-rootfs/dev` directory, any device files accessed within the `./ubuntu-rootfs/` environment will be redirected to the corresponding devices on the host system.\n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ sudo mount -o bind /dev ./dev\n",
    "```\n",
    "\n",
    "This ensures that the processes running within the `./ubuntu-rootfs/` environment can interact with the necessary devices as if they were directly accessing them on the host system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have mounted the necessary file systems, we use the `chroot` command to change the root directory to the `./ubuntu-rootfs/` directory. \n",
    "\n",
    "```\n",
    "chroot ./ubuntu-rootfs /bin/bash\n",
    "```\n",
    "\n",
    "```sh\n",
    "alexfidalgo@alexfidalgo:~/ubuntu-rootfs$ cd /home/alexfidalgo\n",
    "alexfidalgo@alexfidalgo:~$ sudo chroot ./ubuntu-rootfs /bin/bash\n",
    "root@alexfidalgo:/# \n",
    "```\n",
    "\n",
    "- **`sudo`**: Runs the command with superuser (root) privileges.\n",
    "- **`chroot`**: The command to change the root directory.\n",
    "- **`./ubuntu-rootfs`**: The new root directory.\n",
    "- **`/bin/bash`**: The command to run within the new root environment, which in this case is a bash shell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change to the root directory using `chroot` is only valid for the current session. Once you close the terminal or exit the `chroot` environment, the change is no longer in effect. Here’s what happens:\n",
    "\n",
    "- **Chroot Session**: The `chroot` command changes the root directory for the current process and its children. This means any command you run after `chroot` will see the new root directory as `/`.\n",
    "- **Scope**: This change is only effective for the current shell session. If you open a new terminal or exit the current session, you will return to the original root filesystem of your host.\n",
    "\n",
    "When you want to exit the `chroot` environment and return to your host's original root filesystem, you simply type `exit` or press `Ctrl+D`:\n",
    "\n",
    "- The `chroot` environment is temporary and only affects the current terminal session.\n",
    "- Exiting the `chroot` environment returns you to the original root filesystem of the host.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `chroot` command requires a shell or an executable to be specified so that it can start an interactive session or run commands within the new root filesystem. In this case, `/bin/bash` is specified to start a bash shell within the new root environment. Here's why:\n",
    "\n",
    "- **Purpose**: Specifying `/bin/bash` provides an interactive shell within the `chroot` environment. This allows you to run commands, navigate the filesystem, and perform tasks within the new root.\n",
    "- **Functionality**: Without specifying an executable, `chroot` wouldn't know what program to run after changing the root directory. By specifying `/bin/bash`, you instruct `chroot` to start the bash shell, which then takes over and provides an interactive session.\n",
    "\n",
    "\n",
    "- You could specify other executables or scripts to run instead of `/bin/bash`, depending on what you want to achieve. For example:\n",
    "    ```sh\n",
    "    sudo chroot ./ubuntu-rootfs /bin/sh\n",
    "    ```\n",
    "    or\n",
    "    ```sh\n",
    "    sudo chroot ./ubuntu-rootfs /usr/bin/python3\n",
    "    ```\n",
    "- However, for general usage and troubleshooting, starting a shell like `bash` or `sh` is most common because it provides a flexible environment for running various commands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Applications within the Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our container environment is set up, we can install and run applications within it.\n",
    "\n",
    "In this example, we install Nginx web server to demonstrate how applications behave within the container.\n",
    "\n",
    "```\n",
    "(container) $ apt update\n",
    "(container) $ apt install nginx\n",
    "(container) $ service nginx start\n",
    "```\n",
    "\n",
    "```sh\n",
    "root@alexfidalgo:/# service nginx start\n",
    " * Starting nginx nginx                                                                                                                [ OK ] \n",
    "root@alexfidalgo:/# service nginx status\n",
    " * nginx is running\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `ps fuxa` is used to display a detailed list of processes running on the system, with additional formatting options.\n",
    "\n",
    "- **`ps`**: The command to display information about active processes.\n",
    "- **`f`**: Display a full-format listing and show processes in a hierarchical format (process tree).\n",
    "- **`u`**: Display the process information in a user-oriented format, showing user-related columns like user ID, CPU usage, memory usage, etc.\n",
    "- **`x`**: Include processes that do not have a controlling terminal. This means it will list all processes, not just those running in the current terminal session.\n",
    "- **`a`**: Include all processes on a terminal, including those of other users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "root@alexfidalgo:/# ps fuxa\n",
    "```\n",
    "Retorna várias linhas, entre elas:\n",
    "\n",
    "```sh\n",
    "000        1513  0.0  0.2   8748  5492 tty1     S+   14:10   0:00  \\_ -bash\n",
    "```\n",
    "\n",
    "Num terminal normal dessa VM:\n",
    "\n",
    "```\n",
    "alexfidalgo@alexfidalgo:~$ ps\n",
    "  PID TTY          TIME CMD\n",
    " 1513 tty1     00:00:00 bash\n",
    "16793 tty1     00:00:00 ps\n",
    "```\n",
    "\n",
    "The process with PID `1513` shown in both outputs is indeed the `bash` shell that you started when you chrooted into the `ubuntu-rootfs` environment.\n",
    "\n",
    "**Inside the `chroot` Environment**:\n",
    "  - When you chroot into `ubuntu-rootfs` and start a `bash` shell, it is assigned a PID.\n",
    "  - In your `ps fuxa` output inside the `chroot` environment, you see:\n",
    "    ```sh\n",
    "    000        1513  0.0  0.2   8748  5492 tty1     S+   14:10   0:00  \\_ -bash\n",
    "    ```\n",
    "    This indicates that the `bash` process with PID `1513` is running on `tty1`.\n",
    "\n",
    "**Outside the `chroot` Environment**:\n",
    "  - When you run `ps` from a normal terminal in the VM (outside the `chroot`), you see:\n",
    "    ```sh\n",
    "    PID TTY          TIME CMD\n",
    "    1513 tty1     00:00:00 bash\n",
    "    ```\n",
    "    This indicates that the same `bash` process with PID `1513` is running on `tty1`.\n",
    "\n",
    "The PID `1513` in both outputs refers to the same `bash` process. This is because the `chroot` command does not change the PID namespace; it only changes the root directory for the process. Therefore, the process ID remains the same and is visible both inside and outside the `chroot` environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containers and Images Practice (3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar o docker (https://docs.docker.com/engine/install/ubuntu/).\n",
    "\n",
    "The `sudo groupadd docker` command creates a new group named `docker` on your system.\n",
    "- `groupadd`: The command used to create a new group on the system.\n",
    "- `docker`: The name of the group you are creating.\n",
    "\n",
    "The primary purpose of creating the `docker` group is to allow non-root users to run Docker commands. By adding a user to the `docker` group, you give that user permission to use the Docker daemon without needing to prepend `sudo` to Docker commands.\n",
    "\n",
    "1. **Create the Docker Group:**\n",
    "   ```sh\n",
    "   sudo groupadd docker\n",
    "   ```\n",
    "\n",
    "2. **Add Your User to the Docker Group:**\n",
    "   ```sh\n",
    "   sudo usermod -aG docker $USER\n",
    "   ```\n",
    "\n",
    "```sh\n",
    "sudo systemctl enable docker.service\n",
    "```\n",
    "\n",
    "- `systemctl`: A command used to introspect and control the systemd system and service manager.\n",
    "- `enable`: Configures the specified service to start automatically at boot time.\n",
    "- `docker.service`: Specifies the Docker service unit file, which manages the Docker daemon.\n",
    "\n",
    "By running this command, you ensure that the Docker daemon (`dockerd`) will start automatically whenever your system boots up. This is essential for ensuring that Docker containers and services are available immediately after the system starts.\n",
    "\n",
    "```sh\n",
    "sudo systemctl enable containerd.service\n",
    "```\n",
    "\n",
    "- `systemctl`: A command used to introspect and control the systemd system and service manager.\n",
    "- `enable`: Configures the specified service to start automatically at boot time.\n",
    "- `containerd.service`: Specifies the `containerd` service unit file, which manages the container runtime used by Docker.\n",
    "\n",
    "By running this command, you ensure that `containerd`, the container runtime responsible for managing the lifecycle of containers, will start automatically at boot time. This is important because Docker relies on `containerd` to run containers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you install Docker, you get two major components:\n",
    "- the Docker client\n",
    "- the Docker daemon (sometimes called “server” or “engine”)\n",
    "\n",
    "In a default Linux installation, the client talks to the daemon via a local IPC/Unix socket at `/var/run/docker.sock`.\n",
    "\n",
    "You can test that the client\n",
    "and daemon are running and can talk to each other with the `docker version` command.\n",
    "\n",
    "```sh\n",
    "alex@alex-inspiron:~$ docker version\n",
    "Client: Docker Engine - Community\n",
    " Version:           27.0.3\n",
    " API version:       1.43 (downgraded from 1.46)\n",
    " Go version:        go1.21.11\n",
    " Git commit:        7d4bcd8\n",
    " Built:             Sat Jun 29 00:02:33 2024\n",
    " OS/Arch:           linux/amd64\n",
    " Context:           default\n",
    "\n",
    "Server:\n",
    " Engine:\n",
    "  Version:          24.0.5\n",
    "  API version:      1.43 (minimum version 1.12)\n",
    "  Go version:       go1.20.8\n",
    "  Git commit:       a61e2b4\n",
    "  Built:            Sat Oct  7 00:14:30 2023\n",
    "  OS/Arch:          linux/amd64\n",
    "  Experimental:     false\n",
    " containerd:\n",
    "  Version:          v1.6.21\n",
    "  GitCommit:        3dce8eb055cbb6872793272b4f20ed16117344f8\n",
    " runc:\n",
    "  Version:          1.1.7\n",
    "  GitCommit:        \n",
    " docker-init:\n",
    "  Version:          0.19.0\n",
    "  GitCommit:        de40ad0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker image: object that contains an OS filesystem and an application. It's like a VM template (a stopped VM). An image is a stopped container.\n",
    "\n",
    "Getting images onto your Docker host is called _pulling_.\n",
    "\n",
    "```sh\n",
    "docker image pull ubuntu:latest\n",
    "```\n",
    "\n",
    "An image contains enough of an operating system (OS), as well as all the code and dependencies to run whatever application it’s designed for. The ubuntu image that we’ve pulled has a stripped-down version of the Ubuntu Linux filesystem including a few of the common Ubuntu utilities.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an image pulled locally on our Docker host, we can use the `docker container run` command to launch a container from it.\n",
    "\n",
    "```sh\n",
    "docker container run -it ubuntu:latest /bin/bash\n",
    "```\n",
    "\n",
    "The command is used to start a new container from the `ubuntu:latest` image and provide an interactive terminal session inside the container. \n",
    "\n",
    "The shell prompt has changed:\n",
    "\n",
    "```sh\n",
    "root@2caf2e44ee86:/# \n",
    "```\n",
    "\n",
    "Your shell is now attached to the shell of the new container - you are literally inside of the new container.\n",
    "\n",
    "- `docker container run`: This command creates and starts a new container.\n",
    "\n",
    "- `-it`: This is a combination of two flags:\n",
    "  - `-i` (interactive): Keeps the standard input (stdin) of the container open, allowing you to interact with the container.\n",
    "  - `-t` (tty): Allocates a pseudo-TTY, which provides a terminal interface for the container. This is what allows you to interact with the container in a terminal-like environment.\n",
    "\n",
    "- `ubuntu:latest`: This specifies the image to use for the container. In this case, it is the `ubuntu` image with the `latest` tag. If the image is not already present locally, Docker will pull it from the Docker Hub repository.\n",
    "\n",
    "- `/bin/bash`: This is the command to run inside the container once it starts. Here, it launches the Bash shell, giving you a command-line interface inside the Ubuntu container.\n",
    "\n",
    "When you run this command, you will enter an interactive Bash shell inside the newly created Ubuntu container, allowing you to execute commands as if you were working directly on an Ubuntu machine. To exit the container's Bash shell, you can type `exit` or press `Ctrl+D`.\n",
    "\n",
    "The `-it` flags tell the daemon to make the container interactive and to attach our current terminal to the shell of the container.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "root@2caf2e44ee86:/# ps -elf\n",
    "F S UID          PID    PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD\n",
    "4 S root           1       0  0  80   0 -  1147 do_wai 02:19 pts/0    00:00:00 /bin/bash\n",
    "4 R root          11       1 99  80   0 -  1984 -      02:25 pts/0    00:00:00 ps -elf\n",
    "```\n",
    "\n",
    "Inside the Linux container there are only two processes running:\n",
    "- PID 1. This is the /bin/bash process that we told the container to run with the docker container run command.\n",
    "- PID 11. This is the ps -elf command/process that we ran to list the running processes.\n",
    "\n",
    "The presence of the ps -elf process in the Linux output above could be a bit misleading as it is a short-lived process that dies as soon as the ps command exits. This means that the only long-running process inside of the container is the /bin/bash process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Press `Ctrl-PQ` to exit the container without terminating it. This will land you back in the shell of your Docker host. \n",
    "\n",
    "```sh\n",
    "alex@alex-inspiron:~$ ps -elf\n",
    "F S UID          PID    PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD\n",
    "4 S root           1       0  0  80   0 - 42095 -      22:39 ?        00:00:05 /sbin/init splash\n",
    "1 S root           2       0  0  80   0 -     0 -      22:39 ?        00:00:00 [kthreadd]\n",
    "1 I root           3       2  0  60 -20 -     0 -      22:39 ?        00:00:00 [rcu_gp]\n",
    "<SNIP>\n",
    "```\n",
    "\n",
    "Notice how many more processes are running on your Docker host compared to the containers we ran.\n",
    "\n",
    "```sh\n",
    "alex@alex-inspiron:~$ docker container ls\n",
    "CONTAINER ID   IMAGE           COMMAND       CREATED          STATUS          PORTS     NAMES\n",
    "2caf2e44ee86   ubuntu:latest   \"/bin/bash\"   11 minutes ago   Up 11 minutes             quizzical_yonath\n",
    "```\n",
    "\n",
    "The output above shows a single running container. This is the container that you created earlier. The presence of your container in this output proves that it’s still running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attaching to running containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can attach your shell to running containers with the `docker container exec` command. As the container from the previous steps is still running, let’s connect back to it.\n",
    "\n",
    "```sh\n",
    "docker container exec -it quizzical_yonath bash\n",
    "```\n",
    "\n",
    "Used to open an interactive Bash shell inside a running Docker container. After issuing the previous command, I am inside a container:\n",
    "\n",
    "```sh\n",
    "root@2caf2e44ee86:/# ps\n",
    "    PID TTY          TIME CMD\n",
    "     12 pts/1    00:00:00 bash\n",
    "     20 pts/1    00:00:00 ps\n",
    "```\n",
    "\n",
    "We used the `-it` options to attach our shell to the container’s shell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloning an app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "git clone https://github.com/nigelpoulton/psweb.git\n",
    "cd psweb\n",
    "```\n",
    "\n",
    "```sh\n",
    "alex@alex-inspiron:~/Documents/Projects/CloudComputing/ContainersAndImagesPractice/psweb$ cat Dockerfile\n",
    "# Test web-app to use with Pluralsight courses and Docker Deep Dive book\n",
    "FROM alpine\n",
    "\n",
    "LABEL maintainer=\"nigelpoulton@hotmail.com\"\n",
    "\n",
    "# Install Node and NPM\n",
    "RUN apk add --update nodejs npm curl\n",
    "\n",
    "# Copy app to /src\n",
    "COPY . /src\n",
    "\n",
    "WORKDIR /src\n",
    "\n",
    "# Install dependencies\n",
    "RUN  npm install\n",
    "\n",
    "EXPOSE 8080\n",
    "\n",
    "ENTRYPOINT [\"node\", \"./app.js\"]\n",
    "alex@alex-inspiron:~/Documents/Pro\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line represents an instruction that is used to build an image.\n",
    "\n",
    "Use the command below to create a new image using the instructions contained in the Dockerfile. This example creates a new Docker image called `test:latest`.\n",
    "\n",
    "```sh\n",
    "docker image build -t test:latest .\n",
    "```\n",
    "\n",
    "- `docker image build`: This is the base command to build a Docker image from a Dockerfile.\n",
    "\n",
    "- `-t test:latest`: The `-t` option allows you to specify a name and optionally a tag for the image being built. In this case, `test` is the name of the image and `latest` is the tag. Tags are useful for versioning and identifying different builds of the same image.\n",
    "\n",
    "- `.`: This specifies the build context. The dot (`.`) represents the current directory. Docker will look for a Dockerfile in this directory to use for building the image.\n",
    "\n",
    "The Dockerfile contains a set of instructions that specify how to build the image, including which base image to use, what software to install, what files to copy, and what commands to run. Docker processes the instructions in the Dockerfile step by step, creating intermediate images for each instruction. It starts with the base image and layers additional instructions on top of it. Once the image is built, Docker tags it with the name `test` and the tag `latest`. This makes it easier to reference the image in future commands, such as running a container from it.\n",
    "\n",
    "Suppose you have a web application written in Python, and you want to create a Docker image that includes the application code and its dependencies. You would write a Dockerfile that specifies the base image (e.g., `python:3.8`), copies your application code into the image, installs the dependencies, and sets the command to run the application. Running the `docker image build -t test:latest .` command in the directory containing your Dockerfile would create the image you need.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "alex@alex-inspiron:~/Documents/Projects/CloudComputing/ContainersAndImagesPractice/psweb$ docker image ls\n",
    "REPOSITORY   TAG       IMAGE ID       CREATED          SIZE\n",
    "test         latest    e53f413f5050   25 seconds ago   95MB\n",
    "ubuntu       latest    35a88802559d   6 weeks ago      78.1MB\n",
    "```\n",
    "\n",
    "You now have a newly built image with the app inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running a container from the image and test the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "docker container run -d --name web1 -p 8080:8080 test:latest\n",
    "```\n",
    "\n",
    "The command is used to start a new Docker container from the `test:latest` image, running it in detached mode and mapping a port from the host to the container. \n",
    "\n",
    "- `docker container run`: This is the base command to create and start a new container from a specified image.\n",
    "\n",
    "- `-d`: This option runs the container in detached mode, meaning the container will run in the background and you will get the command prompt back immediately. You can use `docker logs` and `docker exec` to interact with it later.\n",
    "\n",
    "- `--name web1`: This option names the container `web1`. Naming a container makes it easier to reference in future commands, rather than using the container ID.\n",
    "\n",
    "- `-p 8080:8080`: This option publishes a container's port to the host. It maps port 8080 on the host to port 8080 in the container. This allows you to access the service running in the container via `http://localhost:8080` on your host machine.\n",
    "\n",
    "- `test:latest`: This specifies the image to use for the container. In this case, it is the `test` image with the `latest` tag.\n",
    "\n",
    "Open a web browser and navigate to the DNS name or IP address of the host that you are running the container from and point it to port 8080. \n",
    "\n",
    "<img src=\"figs/aula03/web_app.png\" style=\"width:50%;\"/>\n",
    "\n",
    "You’ve taken an application and containerized it (built a Docker image from it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a container image for use on Amazon ECS (3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install latest version of the AWS CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "unzip awscliv2.zip\n",
    "sudo ./aws/install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving an image through its lifecycle in Amazon ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "touch Dockerfile\n",
    "```\n",
    "\n",
    "```sh\n",
    "FROM public.ecr.aws/amazonlinux/amazonlinux:latest\n",
    "\n",
    "# Install dependencies\n",
    "RUN yum update -y && \\\n",
    " yum install -y httpd\n",
    "\n",
    "# Install apache and write hello world message\n",
    "RUN echo 'Hello World!' > /var/www/html/index.html\n",
    "\n",
    "# Configure apache\n",
    "RUN echo 'mkdir -p /var/run/httpd' >> /root/run_apache.sh && \\\n",
    " echo 'mkdir -p /var/lock/httpd' >> /root/run_apache.sh && \\\n",
    " echo '/usr/sbin/httpd -D FOREGROUND' >> /root/run_apache.sh && \\\n",
    " chmod 755 /root/run_apache.sh\n",
    "\n",
    "EXPOSE 80\n",
    "\n",
    "CMD /root/run_apache.sh\n",
    "```\n",
    "\n",
    "This Dockerfile uses the public Amazon Linux 2 image hosted on Amazon ECR Public. The RUN instructions update the package caches, installs some software packages for the web server, and then write the \"Hello World!\" content to the web servers document root. The EXPOSE instruction exposes port 80 on the container, and the CMD instruction starts the web server.\n",
    "\n",
    "```sh\n",
    "docker build -t hello-world .\n",
    "docker run -t -i -p 80:80 hello-world\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Authenticate to your default registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate the Docker CLI to your default registry. That way, the docker command can push and pull images with Amazon ECR. \n",
    "\n",
    "```sh\n",
    "aws ecr get-login-password --region region | docker login --username AWS --password-stdin aws_account_id.dkr.ecr.region.amazonaws.com\n",
    "```\n",
    "\n",
    "```sh\n",
    "aws ecr get-login-password --region sa-east-1 | docker login --username AWS --password-stdin 093511299840.dkr.ecr.sa-east-1.amazonaws.com\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "alex@alex-inspiron:~$ aws ecr create-repository --repository-name hello-repository --region sa-east-1\n",
    "{\n",
    "    \"repository\": {\n",
    "        \"repositoryArn\": \"arn:aws:ecr:sa-east-1:093511299840:repository/hello-repository\",\n",
    "        \"registryId\": \"093511299840\",\n",
    "        \"repositoryName\": \"hello-repository\",\n",
    "        \"repositoryUri\": \"093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository\",\n",
    "        \"createdAt\": \"2024-07-21T23:06:23.314000-03:00\",\n",
    "        \"imageTagMutability\": \"MUTABLE\",\n",
    "        \"imageScanningConfiguration\": {\n",
    "            \"scanOnPush\": false\n",
    "        },\n",
    "        \"encryptionConfiguration\": {\n",
    "            \"encryptionType\": \"AES256\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Push an image to Amazon ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "docker tag hello-world:latest 093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository\n",
    "```\n",
    "\n",
    "```sh\n",
    "alex@alex-inspiron:~$ docker push 093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository\n",
    "Using default tag: latest\n",
    "The push refers to repository [093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository]\n",
    "0e57499debe7: Pushed \n",
    "162da71b3fb1: Pushed \n",
    "9946012d1b27: Pushed \n",
    "fcdf0d346db9: Pushed \n",
    "latest: digest: sha256:d84596be8357c2630797e5f4f9388255b855899cc3858cbe4d81ac7bd57a8255 size: 1155\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sa-east-1.console.aws.amazon.com/ecr/private-registry/repositories?region=sa-east-1\n",
    "\n",
    "<img src=\"figs/AWS/3_2/amazon_ecr.png\" style=\"width:50%;\"/>\n",
    "\n",
    "<img src=\"figs/AWS/3_2/images_in_repository.png\" style=\"width:50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pull an image from Amazon ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "alex@alex-inspiron:~$ docker pull 093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository:latest\n",
    "latest: Pulling from hello-repository\n",
    "Digest: sha256:d84596be8357c2630797e5f4f9388255b855899cc3858cbe4d81ac7bd57a8255\n",
    "Status: Downloaded newer image for 093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository:latest\n",
    "093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository:latest\n",
    "alex@alex-inspiron:~$ docker images\n",
    "REPOSITORY                                                      TAG       IMAGE ID       CREATED       SIZE\n",
    "093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository   latest    dddb51019d21   7 hours ago   270MB\n",
    "hello-world                                                     latest    dddb51019d21   7 hours ago   270MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "alex@alex-inspiron:~$ aws ecr batch-delete-image --repository-name hello-repository --image-ids imageTag=latest --region sa-east-1\n",
    "{\n",
    "    \"imageIds\": [\n",
    "        {\n",
    "            \"imageDigest\": \"sha256:d84596be8357c2630797e5f4f9388255b855899cc3858cbe4d81ac7bd57a8255\",\n",
    "            \"imageTag\": \"latest\"\n",
    "        }\n",
    "    ],\n",
    "    \"failures\": []\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete a repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "alex@alex-inspiron:~$ aws ecr delete-repository --repository-name hello-repository --force --region sa-east-1\n",
    "{\n",
    "    \"repository\": {\n",
    "        \"repositoryArn\": \"arn:aws:ecr:sa-east-1:093511299840:repository/hello-repository\",\n",
    "        \"registryId\": \"093511299840\",\n",
    "        \"repositoryName\": \"hello-repository\",\n",
    "        \"repositoryUri\": \"093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository\",\n",
    "        \"createdAt\": \"2024-07-21T23:06:23.314000-03:00\",\n",
    "        \"imageTagMutability\": \"MUTABLE\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a container image for use on Amazon ECS\n",
    "\n",
    "Amazon Elastic Container Service (ECS) uses Docker images in task definitions to launch containers. Amazon ECS is part of Amazon Elastic Compute Cloud, which allows users to rent virtual computers on which to run their own computer applications. \n",
    "\n",
    "The purpose of the steps outlined here is to walk you through creating your first Docker image and pushing that image to Amazon Elastic Container Registry (ECR) for use in your Amazon ECS task definitions.\n",
    "\n",
    "##### Create a Docker Image\n",
    "\n",
    "A Dockerfile is a manifest that describes the base image to use for your Docker image and what you want installed and running on it.\n",
    "\n",
    "```sh\n",
    "touch Dockerfile\n",
    "```\n",
    "\n",
    "```sh\n",
    "FROM public.ecr.aws/amazonlinux/amazonlinux:latest\n",
    "\n",
    "# Update installed packages and install Apache\n",
    "RUN yum update -y && \\\n",
    " yum install -y httpd\n",
    "\n",
    "# Write hello world message\n",
    "RUN echo 'Hello World!' > /var/www/html/index.html\n",
    "\n",
    "# Configure Apache\n",
    "RUN echo 'mkdir -p /var/run/httpd' >> /root/run_apache.sh && \\\n",
    " echo 'mkdir -p /var/lock/httpd' >> /root/run_apache.sh && \\\n",
    " echo '/usr/sbin/httpd -D FOREGROUND' >> /root/run_apache.sh && \\\n",
    " chmod 755 /root/run_apache.sh\n",
    "\n",
    "EXPOSE 80\n",
    "\n",
    "CMD /root/run_apache.sh\n",
    "```\n",
    "```sh\n",
    "docker build -t hello-world .\n",
    "```\n",
    "\n",
    "```sh\n",
    "docker images --filter reference=hello-world\n",
    "```\n",
    "\n",
    "Run the newly built image. The `-p 80:80` option maps the exposed port 80 on the container to port 80 on the host system.\n",
    "\n",
    "```sh\n",
    "docker run -t -i -p 80:80 hello-world\n",
    "```\n",
    "\n",
    "<img src=\"figs/AWS/3_2/localhost.png\" style=\"width:50%;\"/>\n",
    "\n",
    "##### Push your image to Amazon ECR\n",
    "\n",
    "Create an Amazon ECR repository to store your `hello-world` image. \n",
    "\n",
    "```sh\n",
    "alex@alex-inspiron:~/Documents/Projects/CloudComputing/ContainersAndImagesPractice/aws3_3$ aws ecr create-repository --repository-name hello-repository --region sa-east-1\n",
    "{\n",
    "    \"repository\": {\n",
    "        \"repositoryArn\": \"arn:aws:ecr:sa-east-1:093511299840:repository/hello-repository\",\n",
    "        \"registryId\": \"093511299840\",\n",
    "        \"repositoryName\": \"hello-repository\",\n",
    "        \"repositoryUri\": \"093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository\",\n",
    "        \"createdAt\": \"2024-07-22T22:15:57.166000-03:00\",\n",
    "        \"imageTagMutability\": \"MUTABLE\",\n",
    "        \"imageScanningConfiguration\": {\n",
    "            \"scanOnPush\": false\n",
    "        },\n",
    "        \"encryptionConfiguration\": {\n",
    "            \"encryptionType\": \"AES256\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "Tag the `hello-world` image with the `repositoryUri` value from the previous step.\n",
    "\n",
    "```sh\n",
    "docker tag hello-world 093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository\n",
    "```\n",
    "\n",
    "The command creates a new tag for the `hello-world` image, allowing you to push it to the specified Amazon ECR repository (`093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository`).\n",
    "\n",
    "Run the `aws ecr get-login-password` command.\n",
    "\n",
    "```sh\n",
    "aws ecr get-login-password --region sa-east-1 | docker login --username AWS --password-stdin 093511299840.dkr.ecr.sa-east-1.amazonaws.com\n",
    "```\n",
    "\n",
    "Push the image to Amazon ECR with the `repositoryUri` value.\n",
    "\n",
    "```sh\n",
    "docker push 093511299840.dkr.ecr.sa-east-1.amazonaws.com/hello-repository\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
